package io.leavesfly.tinyai.deepseek.v3.training;

import io.leavesfly.tinyai.deepseek.v3.DeepSeekV3Config;
import io.leavesfly.tinyai.deepseek.v3.DeepSeekV3Model;
import io.leavesfly.tinyai.deepseek.v3.TaskType;

import java.io.*;
import java.util.*;

/**
 * DeepSeek-V3å®Œæ•´è®­ç»ƒæ¼”ç¤º V2ç‰ˆæœ¬
 * 
 * å‚è€ƒGPT1TrainDemoV2çš„å®ç°æ–¹å¼ï¼Œæä¾›å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼š
 * 1. å‡†å¤‡çœŸå®çš„æ•™å­¦æ•°æ®é›†ï¼ˆé€‚ç”¨äºæ•™è‚²å­¦ä¹ ï¼‰
 * 2. é¢„è®­ç»ƒé˜¶æ®µ - åŸºç¡€è¯­è¨€å»ºæ¨¡è®­ç»ƒ
 * 3. åè®­ç»ƒé˜¶æ®µ - ä»»åŠ¡ç‰¹å®šå¾®è°ƒ
 * 4. æ¨ç†é˜¶æ®µ - å¤šç§ç”Ÿæˆç­–ç•¥æ¼”ç¤º
 * 
 * æ”¹è¿›ç‚¹ï¼š
 * - ä½¿ç”¨çœŸå®æ–‡æœ¬æ•°æ®è€Œééšæœºæ•°æ®
 * - æ”¯æŒä»æ–‡ä»¶åŠ è½½æ•°æ®é›†
 * - åŒ…å«æ•°æ®é›†è‡ªåŠ¨ç”ŸæˆåŠŸèƒ½
 * - è¯¦ç»†çš„è®­ç»ƒè¿‡ç¨‹è¯´æ˜å’Œæ—¥å¿—
 * - å®Œæ•´çš„é¢„è®­ç»ƒ-åè®­ç»ƒ-æ¨ç†æµç¨‹
 * 
 * V3ç‰¹è‰²ï¼š
 * - MoEæ¶æ„çš„è´Ÿè½½å‡è¡¡è®­ç»ƒ
 * - ä»»åŠ¡æ„ŸçŸ¥çš„æ•°æ®æ ‡æ³¨å’Œè®­ç»ƒ
 * - ä»£ç ç”Ÿæˆä»»åŠ¡çš„ä¸“é—¨æ”¯æŒ
 * 
 * @author leavesfly
 * @version 2.0
 */
public class DeepSeekV3TrainDemoV2 {
    
    private static SimpleTokenizer sharedTokenizer = new SimpleTokenizer();
    
    private static final String DATA_DIR = "./data/deepseek_v3_training";
    private static final String CHECKPOINT_DIR = "./checkpoints/deepseek_v3_v2";
    
    public static void main(String[] args) {
        System.out.println("=".repeat(80));
        System.out.println("DeepSeek-V3 å®Œæ•´è®­ç»ƒä¸æ¨ç†æ¼”ç¤º V2");
        System.out.println("é€‚ç”¨äºæ•™å­¦å’Œå­¦ä¹ çš„å°å‹æ•°æ®é›†è®­ç»ƒæ–¹æ¡ˆ");
        System.out.println("=".repeat(80));
        
        try {
            // æ­¥éª¤0: å‡†å¤‡æ•°æ®é›†æ–‡ä»¶
            prepareDatasets();
            
            // æ­¥éª¤1: é¢„è®­ç»ƒ
            DeepSeekV3Model pretrainedModel = runPretraining();
            
            // æ­¥éª¤2: é€šç”¨åè®­ç»ƒï¼ˆä»»åŠ¡æ„ŸçŸ¥å¾®è°ƒï¼‰
            DeepSeekV3Model finetunedModel = runPosttraining(pretrainedModel);
            
            // æ­¥éª¤2B (å¯é€‰): ä»£ç ç”Ÿæˆä¸“é¡¹åè®­ç»ƒ
            // è¯´æ˜ï¼šæ­¤æ­¥éª¤å¼ºåŒ–MoEä¸“å®¶å¯¹ä»£ç ä»»åŠ¡çš„ç‰¹åŒ–èƒ½åŠ›
            DeepSeekV3Model codeSpecializedModel = runCodePosttraining(finetunedModel);
            
            // æ­¥éª¤3: æ¨ç†æµ‹è¯•
            runInference(codeSpecializedModel);
            
            System.out.println("\n" + "=".repeat(80));
            System.out.println("âœ… å®Œæ•´è®­ç»ƒæµç¨‹æ¼”ç¤ºæˆåŠŸ!");
            System.out.println("=".repeat(80));
            
        } catch (Exception e) {
            System.err.println("âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: " + e.getMessage());
            e.printStackTrace();
        }
    }
    
    /**
     * å‡†å¤‡è®­ç»ƒæ•°æ®é›†
     * ç”Ÿæˆpretrainå’Œposttrainæ•°æ®æ–‡ä»¶
     */
    private static void prepareDatasets() throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ“¦ æ­¥éª¤0: å‡†å¤‡è®­ç»ƒæ•°æ®é›†");
        System.out.println("=".repeat(80));
        
        File dataDir = new File(DATA_DIR);
        if (!dataDir.exists()) {
            dataDir.mkdirs();
            System.out.println("âœ“ åˆ›å»ºæ•°æ®ç›®å½•: " + DATA_DIR);
        }
        
        // ç”Ÿæˆé¢„è®­ç»ƒæ•°æ®é›†
        generatePretrainDataset();
        
        // ç”Ÿæˆåè®­ç»ƒæ•°æ®é›†
        generatePosttrainDataset();
        
        System.out.println("\nâœ… æ•°æ®é›†å‡†å¤‡å®Œæˆ!");
    }
    
    /**
     * ç”Ÿæˆé¢„è®­ç»ƒæ•°æ®é›†
     * åŒ…å«æ·±åº¦å­¦ä¹ ã€MoEã€Transformerç­‰é¢†åŸŸçš„æ•™å­¦æ–‡æœ¬
     */
    private static void generatePretrainDataset() throws IOException {
        System.out.println("\nğŸ“ ç”Ÿæˆé¢„è®­ç»ƒæ•°æ®é›†...");
        
        List<String> pretrainTexts = new ArrayList<>();
        
        // 1. MoEå’Œä¸“å®¶ç³»ç»Ÿç›¸å…³çŸ¥è¯† (50æ¡)
        pretrainTexts.addAll(generateMoETexts());
        
        // 2. DeepSeekå’Œå¤§æ¨¡å‹ç›¸å…³çŸ¥è¯† (50æ¡)
        pretrainTexts.addAll(generateDeepSeekTexts());
        
        // 3. ä»»åŠ¡æ„ŸçŸ¥å’Œæ¨ç†ç›¸å…³çŸ¥è¯† (40æ¡)
        pretrainTexts.addAll(generateReasoningTexts());
        
        // 4. ä»£ç ç”Ÿæˆå’Œç¼–ç¨‹ç›¸å…³çŸ¥è¯† (40æ¡)
        pretrainTexts.addAll(generateCodingTexts());
        
        // 5. Transformerå’Œæ³¨æ„åŠ›æœºåˆ¶ (40æ¡)
        pretrainTexts.addAll(generateTransformerTexts());
        
        // 6. æ·±åº¦å­¦ä¹ åŸºç¡€ (30æ¡)
        pretrainTexts.addAll(generateDeepLearningTexts());
        
        // å†™å…¥æ–‡ä»¶
        String filePath = DATA_DIR + "/pretrain.txt";
        writeToFile(pretrainTexts, filePath);
        
        System.out.println("  âœ“ é¢„è®­ç»ƒæ•°æ®: " + pretrainTexts.size() + " æ¡");
        System.out.println("  âœ“ ä¿å­˜è·¯å¾„: " + filePath);
    }
    
    /**
     * ç”Ÿæˆåè®­ç»ƒæ•°æ®é›†
     * åŒ…å«ä»»åŠ¡ç‰¹å®šçš„æŒ‡ä»¤-å›ç­”å¯¹
     */
    private static void generatePosttrainDataset() throws IOException {
        System.out.println("\nğŸ“ ç”Ÿæˆåè®­ç»ƒæ•°æ®é›†...");
        
        List<String> trainTexts = new ArrayList<>();
        List<String> valTexts = new ArrayList<>();
        
        // è®­ç»ƒé›†: 100æ¡ä»»åŠ¡æ„ŸçŸ¥çš„æŒ‡ä»¤-å›ç­”å¯¹
        trainTexts.addAll(generateTaskAwareQA());
        
        // éªŒè¯é›†: ä»è®­ç»ƒé›†ä¸­æŠ½å–15æ¡
        for (int i = 0; i < 15 && i < trainTexts.size(); i++) {
            valTexts.add(trainTexts.get(i));
        }
        
        // å†™å…¥è®­ç»ƒé›†
        String trainPath = DATA_DIR + "/posttrain_train.txt";
        writeToFile(trainTexts, trainPath);
        System.out.println("  âœ“ åè®­ç»ƒè®­ç»ƒé›†: " + trainTexts.size() + " æ¡");
        System.out.println("  âœ“ ä¿å­˜è·¯å¾„: " + trainPath);
        
        // å†™å…¥éªŒè¯é›†
        String valPath = DATA_DIR + "/posttrain_val.txt";
        writeToFile(valTexts, valPath);
        System.out.println("  âœ“ åè®­ç»ƒéªŒè¯é›†: " + valTexts.size() + " æ¡");
        System.out.println("  âœ“ ä¿å­˜è·¯å¾„: " + valPath);
        
        // ç”Ÿæˆä»£ç ä¸“é¡¹è®­ç»ƒæ•°æ®é›†
        generateCodePosttrainDataset();
    }
    
    /**
     * ç”Ÿæˆä»£ç ç”Ÿæˆä¸“é¡¹åè®­ç»ƒæ•°æ®é›†
     * çº¯ä»£ç ä»»åŠ¡æ•°æ®ï¼Œç”¨äºå¼ºåŒ–MoEä¸“å®¶ç‰¹åŒ–èƒ½åŠ›
     */
    private static void generateCodePosttrainDataset() throws IOException {
        System.out.println("\nğŸ“ ç”Ÿæˆä»£ç ä¸“é¡¹åè®­ç»ƒæ•°æ®é›†...");
        
        List<String> codeTrainTexts = new ArrayList<>();
        List<String> codeValTexts = new ArrayList<>();
        
        // è®­ç»ƒé›†: 60æ¡çº¯ä»£ç ä»»åŠ¡é—®ç­”
        codeTrainTexts.addAll(generateCodeQA());
        
        // éªŒè¯é›†: ä»è®­ç»ƒé›†ä¸­æŠ½å–10æ¡
        for (int i = 0; i < 10 && i < codeTrainTexts.size(); i++) {
            codeValTexts.add(codeTrainTexts.get(i));
        }
        
        // å†™å…¥è®­ç»ƒé›†
        String codeTrainPath = DATA_DIR + "/code_posttrain_train.txt";
        writeToFile(codeTrainTexts, codeTrainPath);
        System.out.println("  âœ“ ä»£ç ä¸“é¡¹è®­ç»ƒé›†: " + codeTrainTexts.size() + " æ¡");
        System.out.println("  âœ“ ä¿å­˜è·¯å¾„: " + codeTrainPath);
        
        // å†™å…¥éªŒè¯é›†
        String codeValPath = DATA_DIR + "/code_posttrain_val.txt";
        writeToFile(codeValTexts, codeValPath);
        System.out.println("  âœ“ ä»£ç ä¸“é¡¹éªŒè¯é›†: " + codeValTexts.size() + " æ¡");
        System.out.println("  âœ“ ä¿å­˜è·¯å¾„: " + codeValPath);
    }
    
    /**
     * ç”ŸæˆMoEç›¸å…³æ–‡æœ¬
     */
    private static List<String> generateMoETexts() {
        return Arrays.asList(
            "Mixture of Experts is a neural network architecture that uses multiple expert networks",
            "MoE models route inputs to different expert networks based on learned gating mechanisms",
            "The gating network in MoE decides which experts should process each input",
            "MoE achieves sparse activation by only using a subset of experts for each input",
            "Top K routing selects the K most relevant experts for each input token",
            "Load balancing in MoE ensures all experts are utilized evenly during training",
            "MoE models can scale to billions of parameters while maintaining efficient inference",
            "DeepSeek V3 uses eight expert networks with top two routing strategy",
            "Expert networks in MoE specialize in different aspects of the input distribution",
            "MoE reduces computational cost by activating only a fraction of total parameters",
            "Auxiliary loss in MoE encourages balanced expert utilization",
            "Sparse MoE models achieve better performance than dense models with similar compute",
            "Expert capacity limits the number of tokens each expert can process per batch",
            "MoE routing can be learned jointly with the model during training",
            "Switch Transformer uses one expert per token for extreme sparsity",
            "MoE enables training of very large models on limited hardware resources",
            "Expert parallelism allows MoE layers to scale across multiple devices",
            "Dynamic routing in MoE adapts to different input patterns automatically",
            "MoE models show strong few shot learning capabilities",
            "Load balancing loss prevents expert collapse where some experts are never used",
            "MoE gating uses softmax to produce probability distribution over experts",
            "Hard routing selects top K experts while soft routing uses weighted combination",
            "MoE architecture is particularly effective for multi task learning",
            "Expert dropout can improve MoE model robustness and generalization",
            "MoE models can learn hierarchical specialization across expert networks"
        );
    }
    
    /**
     * ç”ŸæˆDeepSeekç›¸å…³æ–‡æœ¬
     */
    private static List<String> generateDeepSeekTexts() {
        return Arrays.asList(
            "DeepSeek is a series of advanced language models with innovative architectures",
            "DeepSeek V3 combines MoE with task aware routing for improved performance",
            "Task aware architecture in DeepSeek adapts to different downstream tasks",
            "DeepSeek models support reasoning coding math and multimodal tasks",
            "DeepSeek V3 achieves state of the art results on code generation benchmarks",
            "The reasoning module in DeepSeek enhances logical inference capabilities",
            "DeepSeek supports ten programming languages including Python Java and C plus plus",
            "Code quality in DeepSeek is evaluated on correctness readability efficiency and style",
            "DeepSeek V3 uses multi head latent attention for efficient processing",
            "Task type classification helps DeepSeek route inputs to specialized experts",
            "DeepSeek models can handle sequences up to thousands of tokens",
            "The architecture of DeepSeek V3 enables twenty five percent parameter activation",
            "DeepSeek V3 training uses load balanced MoE loss for expert utilization",
            "Inference in DeepSeek V3 is four times faster than equivalent dense models",
            "DeepSeek supports both causal language modeling and instruction tuning",
            "The reflection module in DeepSeek R1 enables self correction during reasoning",
            "DeepSeek models show strong performance on mathematical problem solving",
            "Multi task learning in DeepSeek improves generalization across domains",
            "DeepSeek V3 pre training uses large scale diverse text corpora",
            "Post training in DeepSeek fine tunes the model for specific applications",
            "DeepSeek achieves competitive results while using fewer active parameters",
            "The gating network in DeepSeek learns task specific expert selection",
            "DeepSeek models support both English and Chinese languages",
            "Code synthesis in DeepSeek generates functionally correct programs",
            "DeepSeek V3 architecture enables efficient deployment on edge devices"
        );
    }
    
    /**
     * ç”Ÿæˆæ¨ç†ç›¸å…³æ–‡æœ¬
     */
    private static List<String> generateReasoningTexts() {
        return Arrays.asList(
            "Reasoning in AI involves drawing logical conclusions from available information",
            "Chain of thought prompting improves reasoning by showing intermediate steps",
            "Task aware models adapt their reasoning strategy based on problem type",
            "Mathematical reasoning requires understanding of numerical relationships and operations",
            "Logical inference applies rules to derive new facts from existing knowledge",
            "Multi step reasoning breaks complex problems into manageable sub problems",
            "Reasoning confidence indicates the model certainty in its conclusions",
            "Commonsense reasoning requires understanding of everyday knowledge and context",
            "Analogical reasoning transfers knowledge from familiar to novel situations",
            "Causal reasoning identifies cause and effect relationships between events",
            "Abstract reasoning manipulates concepts without concrete examples",
            "Deductive reasoning applies general principles to specific cases",
            "Inductive reasoning generalizes from specific observations to broad patterns",
            "Abductive reasoning infers the most likely explanation for observations",
            "Spatial reasoning involves understanding geometric relationships and transformations",
            "Temporal reasoning tracks changes and sequences over time",
            "Reasoning modules can be trained to verify their own conclusions",
            "Self correction in reasoning improves accuracy through iterative refinement",
            "Reasoning traces provide interpretability by showing thought process",
            "Meta reasoning involves thinking about thinking and strategy selection"
        );
    }
    
    /**
     * ç”Ÿæˆç¼–ç¨‹ç›¸å…³æ–‡æœ¬
     */
    private static List<String> generateCodingTexts() {
        return Arrays.asList(
            "Programming languages provide formal systems for instructing computers",
            "Python is widely used for machine learning and data science applications",
            "Java is a statically typed object oriented programming language",
            "JavaScript enables interactive web applications in browsers",
            "C plus plus offers low level control with high level abstractions",
            "Code generation models translate natural language to executable programs",
            "Syntax correctness ensures code follows language grammar rules",
            "Code readability makes programs easier to understand and maintain",
            "Algorithm efficiency measures computational complexity and resource usage",
            "Code style guidelines promote consistency across programming projects",
            "Debugging identifies and fixes errors in program logic",
            "Unit testing verifies individual components function correctly",
            "Version control tracks changes and enables collaboration on code",
            "Code refactoring improves structure without changing behavior",
            "Documentation explains code purpose usage and implementation",
            "API design defines interfaces for software components",
            "Error handling manages exceptional conditions gracefully",
            "Code optimization improves performance and resource efficiency",
            "Design patterns provide reusable solutions to common problems",
            "Type systems prevent errors by checking data type compatibility"
        );
    }
    
    /**
     * ç”ŸæˆTransformerç›¸å…³æ–‡æœ¬
     */
    private static List<String> generateTransformerTexts() {
        return Arrays.asList(
            "Transformer architecture revolutionized natural language processing",
            "Self attention computes relationships between all positions in parallel",
            "Multi head attention captures different types of dependencies simultaneously",
            "Positional encoding adds sequence order information to token embeddings",
            "Query key value projections enable flexible attention computation",
            "Scaled dot product attention prevents gradient issues with large dimensions",
            "Attention weights show which input positions influence each output",
            "Layer normalization stabilizes training in deep transformer networks",
            "Feed forward networks process each position independently in transformers",
            "Residual connections enable training of very deep transformer models",
            "Transformer decoder uses masked self attention for autoregressive generation",
            "Cross attention connects encoder and decoder in sequence to sequence tasks",
            "Pre training on large corpora gives transformers broad language understanding",
            "Fine tuning adapts pre trained transformers to downstream tasks efficiently",
            "Transformers eliminate recurrence enabling parallel sequence processing",
            "Attention visualization reveals linguistic patterns learned by the model",
            "Sparse attention reduces computational cost for long sequences",
            "Relative position encoding captures position relationships more flexibly",
            "Transformer XL extends context through segment level recurrence",
            "GPT uses decoder only transformers for language generation"
        );
    }
    
    /**
     * ç”Ÿæˆæ·±åº¦å­¦ä¹ åŸºç¡€æ–‡æœ¬
     */
    private static List<String> generateDeepLearningTexts() {
        return Arrays.asList(
            "Deep learning uses neural networks with multiple layers",
            "Backpropagation computes gradients for training neural networks",
            "Gradient descent optimizes network parameters iteratively",
            "Loss functions measure prediction errors during training",
            "Activation functions introduce non linearity into networks",
            "Batch normalization accelerates training and improves stability",
            "Dropout prevents overfitting by randomly disabling neurons",
            "Learning rate controls optimization step size",
            "Adam optimizer adapts learning rates for each parameter",
            "Regularization techniques prevent models from overfitting",
            "Early stopping monitors validation performance to prevent overfitting",
            "Data augmentation increases training data diversity",
            "Transfer learning reuses knowledge from pre trained models",
            "Neural networks can approximate any continuous function",
            "Deep architectures learn hierarchical feature representations",
            "Convolutional networks excel at processing grid structured data",
            "Recurrent networks handle sequential and temporal data",
            "Attention mechanisms focus on relevant input parts",
            "Skip connections help gradients flow in deep networks",
            "Embedding layers map discrete tokens to continuous vectors"
        );
    }
    
    /**
     * ç”Ÿæˆä»»åŠ¡æ„ŸçŸ¥çš„é—®ç­”å¯¹ï¼ˆåè®­ç»ƒæ•°æ®ï¼‰
     */
    private static List<String> generateTaskAwareQA() {
        List<String> qa = new ArrayList<>();
        
        // MoEç›¸å…³é—®ç­” (20æ¡)
        qa.add("[REASONING] Question: What is Mixture of Experts? Answer: Mixture of Experts is an architecture that uses multiple specialized expert networks with a gating mechanism to route inputs efficiently");
        qa.add("[REASONING] Question: How does MoE routing work? Answer: MoE routing uses a gating network to compute scores for each expert and selects the top K experts to process each input token");
        qa.add("[REASONING] Question: Why is load balancing important in MoE? Answer: Load balancing ensures all experts are utilized evenly preventing some experts from being overused while others remain idle");
        qa.add("[REASONING] Question: What is sparse activation? Answer: Sparse activation means only a subset of model parameters are active for each input reducing computational cost significantly");
        qa.add("[MATH] Question: If MoE has 8 experts and uses top 2 routing what is the activation ratio? Answer: The activation ratio is 2 divided by 8 which equals 0.25 or 25 percent");
        
        // DeepSeekç›¸å…³é—®ç­” (20æ¡)
        qa.add("[GENERAL] Question: What is DeepSeek V3? Answer: DeepSeek V3 is an advanced language model combining MoE architecture with task aware routing for efficient and high quality text generation");
        qa.add("[REASONING] Question: How does task aware architecture help? Answer: Task aware architecture adapts model behavior based on task type routing inputs to experts specialized for reasoning coding math or other domains");
        qa.add("[CODING] Question: What languages does DeepSeek support? Answer: DeepSeek supports ten programming languages including Python Java C plus plus JavaScript Go Rust TypeScript Ruby PHP and Swift");
        qa.add("[CODING] Question: How is code quality evaluated? Answer: Code quality is evaluated on four dimensions correctness readability efficiency and adherence to style guidelines");
        qa.add("[GENERAL] Question: What are DeepSeek advantages? Answer: DeepSeek advantages include efficient sparse computation task adaptive routing strong code generation and fast inference speed");
        
        // ç¼–ç¨‹ç›¸å…³é—®ç­” (20æ¡)
        qa.add("[CODING] Question: What is Python used for? Answer: Python is used for machine learning data science web development automation scientific computing and general purpose programming");
        qa.add("[CODING] Question: Explain object oriented programming. Answer: Object oriented programming organizes code into objects that combine data and methods providing encapsulation inheritance and polymorphism");
        qa.add("[CODING] Question: What is algorithm complexity? Answer: Algorithm complexity measures computational resources required typically expressed as time complexity and space complexity using big O notation");
        qa.add("[CODING] Question: Why is code readability important? Answer: Code readability makes programs easier to understand maintain debug and extend by other developers or future self");
        qa.add("[CODING] Question: What are design patterns? Answer: Design patterns are reusable solutions to common software design problems providing tested templates for solving recurring challenges");
        
        // Transformerç›¸å…³é—®ç­” (20æ¡)
        qa.add("[REASONING] Question: What is self attention? Answer: Self attention computes relationships between all positions in a sequence allowing each position to attend to all other positions in parallel");
        qa.add("[REASONING] Question: Why use multi head attention? Answer: Multi head attention allows the model to attend to different representation subspaces simultaneously capturing diverse types of relationships");
        qa.add("[GENERAL] Question: What is positional encoding? Answer: Positional encoding injects information about token positions into embeddings since transformers have no inherent notion of sequence order");
        qa.add("[REASONING] Question: How does attention scaling work? Answer: Attention scores are scaled by the square root of dimension to prevent extremely small gradients when dot products grow large");
        qa.add("[GENERAL] Question: What is the transformer advantage? Answer: Transformers enable parallel processing of sequences eliminate vanishing gradients and capture long range dependencies effectively");
        
        // æ·±åº¦å­¦ä¹ åŸºç¡€é—®ç­” (20æ¡)
        qa.add("[REASONING] Question: What is backpropagation? Answer: Backpropagation computes gradients of loss with respect to parameters by applying chain rule backwards through the computational graph");
        qa.add("[MATH] Question: How does gradient descent work? Answer: Gradient descent updates parameters by moving in the direction opposite to the gradient scaled by learning rate to minimize loss");
        qa.add("[REASONING] Question: Why use activation functions? Answer: Activation functions introduce non linearity enabling neural networks to learn complex patterns beyond linear relationships");
        qa.add("[GENERAL] Question: What is overfitting? Answer: Overfitting occurs when a model learns training data too well including noise and fails to generalize to new unseen data");
        qa.add("[REASONING] Question: How does dropout prevent overfitting? Answer: Dropout randomly disables neurons during training forcing the network to learn robust features that do not rely on specific neurons");
        
        return qa;
    }
    
    /**
     * ç”Ÿæˆä»£ç ä¸“é¡¹é—®ç­”æ•°æ®ï¼ˆçº¯CODINGä»»åŠ¡ï¼‰
     * ç”¨äºå¼ºåŒ–MoEä¸“å®¶å¯¹ä»£ç ä»»åŠ¡çš„ç‰¹åŒ–èƒ½åŠ›
     */
    private static List<String> generateCodeQA() {
        List<String> codeQA = new ArrayList<>();
        
        // Pythonç›¸å…³é—®ç­” (15æ¡)
        codeQA.add("[CODING] Question: How to define a function in Python? Answer: Use def keyword followed by function name parentheses for parameters and colon then indent the function body");
        codeQA.add("[CODING] Question: What is list comprehension in Python? Answer: List comprehension provides concise syntax to create lists using bracket notation with for loop and optional if condition");
        codeQA.add("[CODING] Question: How to handle exceptions in Python? Answer: Use try block for code that may raise exceptions except block to catch and handle specific exception types and finally for cleanup");
        codeQA.add("[CODING] Question: What are Python decorators? Answer: Decorators are functions that modify behavior of other functions using at symbol syntax wrapping the original function with additional functionality");
        codeQA.add("[CODING] Question: How to read files in Python? Answer: Use open function with file path and mode then read content with read or readlines method always close file or use with statement");
        
        // Javaç›¸å…³é—®ç­” (15æ¡)
        codeQA.add("[CODING] Question: How to declare a class in Java? Answer: Use public class keyword followed by class name then curly braces containing fields methods and constructors");
        codeQA.add("[CODING] Question: What is inheritance in Java? Answer: Inheritance allows a class to inherit fields and methods from parent class using extends keyword promoting code reuse");
        codeQA.add("[CODING] Question: How to create an interface in Java? Answer: Use interface keyword followed by name declare method signatures without implementation classes implement interface with implements keyword");
        codeQA.add("[CODING] Question: What is Java generics? Answer: Generics enable types to be parameters when defining classes interfaces and methods providing compile time type safety");
        codeQA.add("[CODING] Question: How to handle null in Java? Answer: Check for null before dereferencing use Optional class or annotations like NonNull to prevent null pointer exceptions");
        
        // JavaScriptç›¸å…³é—®ç­” (10æ¡)
        codeQA.add("[CODING] Question: What are arrow functions in JavaScript? Answer: Arrow functions provide shorter syntax using arrow notation capture this from enclosing scope unlike regular functions");
        codeQA.add("[CODING] Question: How to handle async operations in JavaScript? Answer: Use promises with then and catch or async await syntax for cleaner asynchronous code handling");
        codeQA.add("[CODING] Question: What is closure in JavaScript? Answer: Closure is a function that remembers variables from its outer scope even after outer function has finished executing");
        codeQA.add("[CODING] Question: How to iterate arrays in JavaScript? Answer: Use for loop forEach map filter or for of loop depending on whether you need transformation filtering or simple iteration");
        codeQA.add("[CODING] Question: What is destructuring in JavaScript? Answer: Destructuring extracts values from arrays or objects into distinct variables using bracket or curly brace syntax");
        
        // C++ç›¸å…³é—®ç­” (10æ¡)
        codeQA.add("[CODING] Question: What are pointers in C plus plus? Answer: Pointers store memory addresses enabling dynamic memory allocation direct memory access and efficient data structure implementation");
        codeQA.add("[CODING] Question: How to use templates in C plus plus? Answer: Templates enable generic programming using template keyword with type parameters allowing code to work with different data types");
        codeQA.add("[CODING] Question: What is RAII in C plus plus? Answer: Resource Acquisition Is Initialization ties resource lifetime to object lifetime using constructors and destructors for automatic resource management");
        codeQA.add("[CODING] Question: How to handle memory in C plus plus? Answer: Use new for dynamic allocation delete to free memory or prefer smart pointers like unique ptr and shared ptr");
        codeQA.add("[CODING] Question: What are virtual functions in C plus plus? Answer: Virtual functions enable polymorphism allowing derived classes to override base class methods using virtual keyword");
        
        // é€šç”¨ç¼–ç¨‹æ¦‚å¿µ (10æ¡)
        codeQA.add("[CODING] Question: What is time complexity? Answer: Time complexity measures how algorithm runtime grows with input size using big O notation like O of n or O of n squared");
        codeQA.add("[CODING] Question: How to optimize code performance? Answer: Profile code identify bottlenecks use efficient algorithms and data structures minimize memory allocations and avoid premature optimization");
        codeQA.add("[CODING] Question: What is recursion? Answer: Recursion is when function calls itself to solve problem by breaking it into smaller subproblems requires base case to terminate");
        codeQA.add("[CODING] Question: How to debug code effectively? Answer: Use debugger set breakpoints inspect variables trace execution flow write unit tests and use logging strategically");
        codeQA.add("[CODING] Question: What is code refactoring? Answer: Refactoring improves code structure readability and maintainability without changing external behavior through small incremental changes");
        
        return codeQA;
    }
    
    /**
     * å°†æ–‡æœ¬åˆ—è¡¨å†™å…¥æ–‡ä»¶
     */
    private static void writeToFile(List<String> texts, String filePath) throws IOException {
        try (BufferedWriter writer = new BufferedWriter(new FileWriter(filePath))) {
            for (String text : texts) {
                writer.write(text);
                writer.newLine();
            }
        }
    }
    
    /**
     * æ‰§è¡Œé¢„è®­ç»ƒ
     */
    private static DeepSeekV3Model runPretraining() throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ“š æ­¥éª¤1: DeepSeek-V3 é¢„è®­ç»ƒ (Pretrain)");
        System.out.println("=".repeat(80));
        
        // 1. è¯»å–æ‰€æœ‰æ•°æ®ç”¨äºæ„å»ºå®Œæ•´è¯æ±‡è¡¨
        System.out.println("\nğŸ“ åŠ è½½æ‰€æœ‰æ•°æ®ä»¥æ„å»ºè¯æ±‡è¡¨...");
        String pretrainPath = DATA_DIR + "/pretrain.txt";
        String posttrainTrainPath = DATA_DIR + "/posttrain_train.txt";
        String posttrainValPath = DATA_DIR + "/posttrain_val.txt";
        
        List<String> pretrainTexts = readFromFile(pretrainPath);
        List<String> posttrainTrainTexts = readFromFile(posttrainTrainPath);
        List<String> posttrainValTexts = readFromFile(posttrainValPath);
        
        System.out.println("  âœ“ é¢„è®­ç»ƒæ•°æ®: " + pretrainTexts.size() + " æ¡");
        System.out.println("  âœ“ åè®­ç»ƒè®­ç»ƒæ•°æ®: " + posttrainTrainTexts.size() + " æ¡");
        System.out.println("  âœ“ åè®­ç»ƒéªŒè¯æ•°æ®: " + posttrainValTexts.size() + " æ¡");
        
        // 2. åŸºäºæ‰€æœ‰æ•°æ®æ„å»ºå®Œæ•´è¯æ±‡è¡¨
        System.out.println("\nğŸ“ æ„å»ºå®Œæ•´è¯æ±‡è¡¨...");
        List<String> allTexts = new ArrayList<>();
        allTexts.addAll(pretrainTexts);
        allTexts.addAll(posttrainTrainTexts);
        allTexts.addAll(posttrainValTexts);
        
        // éå†æ‰€æœ‰æ–‡æœ¬æ„å»ºè¯æ±‡è¡¨
        for (String text : allTexts) {
            // ç§»é™¤ä»»åŠ¡æ ‡ç­¾åå†ç¼–ç 
            String cleanText = removeTaskLabel(text);
            sharedTokenizer.encode(cleanText);
        }
        int vocabSize = sharedTokenizer.getVocabSize();
        
        // å†»ç»“è¯æ±‡è¡¨
        sharedTokenizer.freeze();
        
        System.out.println("  âœ“ å®Œæ•´è¯æ±‡è¡¨å¤§å°: " + vocabSize);
        System.out.println("  âœ“ è¯æ±‡è¡¨å·²å†»ç»“,åç»­ä¸å†å¢åŠ æ–°è¯");
        
        // 3. åˆ›å»ºDeepSeek-V3æ¨¡å‹
        System.out.println("\nğŸ“ åˆ›å»ºDeepSeek-V3æ¨¡å‹...");
        DeepSeekV3Config config = DeepSeekV3Config.createMicroConfig();
        config.setVocabSize(vocabSize);
        
        DeepSeekV3Model model = new DeepSeekV3Model("deepseek-v3-pretrain-v2", config);
        
        System.out.println("  âœ“ æ¨¡å‹é…ç½®: Micro (æ•™å­¦ä¸“ç”¨)");
        System.out.println("  âœ“ è¯æ±‡è¡¨å¤§å°: " + config.getVocabSize());
        System.out.println("  âœ“ éšè—ç»´åº¦: " + config.getNEmbd());
        System.out.println("  âœ“ å±‚æ•°: " + config.getNLayer());
        System.out.println("  âœ“ æ³¨æ„åŠ›å¤´æ•°: " + config.getNHead());
        System.out.println("  âœ“ ä¸“å®¶æ•°é‡: " + config.getNumExperts());
        System.out.println("  âœ“ Top-Ké€‰æ‹©: " + config.getTopK());
        System.out.println("  âœ“ åºåˆ—é•¿åº¦: " + config.getNPositions());
        
        // 4. å‡†å¤‡æ•°æ®é›†
        System.out.println("\nğŸ“ å‡†å¤‡è®­ç»ƒæ•°æ®é›†...");
        DeepSeekV3Dataset dataset = createDatasetFromTexts(
            pretrainTexts,
            config.getNPositions(),
            4,  // batch size
            config.getVocabSize(),
            false  // é¢„è®­ç»ƒä¸ä½¿ç”¨ä»»åŠ¡æ ‡ç­¾
        );
        
        System.out.println("  âœ“ è®­ç»ƒæ ·æœ¬: " + dataset.getSampleCount());
        System.out.println("  âœ“ æ‰¹æ¬¡å¤§å°: 4");
        System.out.println("  âœ“ åºåˆ—é•¿åº¦: " + config.getNPositions());
        
        // 5. é…ç½®è®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®é¢„è®­ç»ƒå™¨...");
        DeepSeekV3Pretrain trainer = new DeepSeekV3Pretrain(model, dataset);
        // ä¿®å¤ï¼šå¢åŠ è®­ç»ƒè½®æ¬¡ï¼Œå‡å°‘warmupStepsä»¥é€‚åº”å°æ•°æ®é›†
        trainer.configure(
            10,         // maxEpochs (å¢åŠ åˆ°10è½®ï¼Œå°æ•°æ®é›†éœ€è¦æ›´å¤šè½®æ¬¡)
            5e-4f,      // learningRate (æé«˜å­¦ä¹ ç‡)
            10,         // warmupSteps (å‡å°‘warmupæ­¥æ•°ï¼Œæ•°æ®å°‘æ—¶éœ€å¿«é€Ÿè¿›å…¥æ­£å¸¸è®­ç»ƒ)
            1.0f        // maxGradNorm
        ).setCheckpoint(CHECKPOINT_DIR + "/pretrain", 100);
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 10 (å°æ•°æ®é›†éœ€è¦æ›´å¤šè½®æ¬¡)");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 5e-4 (æé«˜å­¦ä¹ ç‡åŠ é€Ÿæ”¶æ•›)");
        System.out.println("  âœ“ Warmupæ­¥æ•°: 10 (å‡å°‘warmupé€‚åº”å°æ•°æ®é›†)");
        System.out.println("  âœ“ MoEè´Ÿè½½å‡è¡¡æƒé‡: " + config.getLoadBalanceLossWeight());
        
        // 6. å¼€å§‹è®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹é¢„è®­ç»ƒ...");
        System.out.println("-".repeat(80));
        trainer.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… é¢„è®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ é¢„è®­ç»ƒé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: å­¦ä¹ è¯­è¨€çš„é€šç”¨è¡¨ç¤ºå’ŒMoEè·¯ç”±");
        System.out.println("  - ä»»åŠ¡: å› æœè¯­è¨€å»ºæ¨¡ + MoEè´Ÿè½½å‡è¡¡");
        System.out.println("  - æ•°æ®: å¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬");
        System.out.println("  - ç‰¹è‰²: ç¨€ç–æ¿€æ´»(25%å‚æ•°) + ä¸“å®¶ç½‘ç»œ");
        
        return model;
    }
    
    /**
     * æ‰§è¡Œåè®­ç»ƒ/å¾®è°ƒ
     */
    private static DeepSeekV3Model runPosttraining(DeepSeekV3Model pretrainedModel) throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ¯ æ­¥éª¤2: DeepSeek-V3 åè®­ç»ƒ/å¾®è°ƒ (Posttrain)");
        System.out.println("=".repeat(80));
        
        // 1. åŠ è½½åè®­ç»ƒæ•°æ®
        System.out.println("\nğŸ“ åŠ è½½åè®­ç»ƒæ•°æ®...");
        String trainPath = DATA_DIR + "/posttrain_train.txt";
        String valPath = DATA_DIR + "/posttrain_val.txt";
        
        List<String> trainTexts = readFromFile(trainPath);
        List<String> valTexts = readFromFile(valPath);
        
        System.out.println("  âœ“ è®­ç»ƒé›†: " + trainTexts.size() + " æ¡");
        System.out.println("  âœ“ éªŒè¯é›†: " + valTexts.size() + " æ¡");
        
        // 2. å‡†å¤‡æ•°æ®é›†ï¼ˆå¸¦ä»»åŠ¡æ ‡ç­¾ï¼‰
        System.out.println("\nğŸ“ å‡†å¤‡åè®­ç»ƒæ•°æ®é›†ï¼ˆä»»åŠ¡æ„ŸçŸ¥ï¼‰...");
        DeepSeekV3Config config = pretrainedModel.getConfig();
        
        DeepSeekV3Dataset trainDataset = createDatasetFromTexts(
            trainTexts,
            config.getNPositions(),
            2,  // batch size
            config.getVocabSize(),
            true  // ä½¿ç”¨ä»»åŠ¡æ ‡ç­¾
        );
        
        DeepSeekV3Dataset valDataset = createDatasetFromTexts(
            valTexts,
            config.getNPositions(),
            1,  // batch size
            config.getVocabSize(),
            true  // ä½¿ç”¨ä»»åŠ¡æ ‡ç­¾
        );
        
        System.out.println("  âœ“ è®­ç»ƒæ ·æœ¬: " + trainDataset.getSampleCount());
        System.out.println("  âœ“ éªŒè¯æ ·æœ¬: " + valDataset.getSampleCount());
        System.out.println("  âœ“ ä»»åŠ¡æ„ŸçŸ¥æ ‡æ³¨: å¯ç”¨");
        
        // 3. é…ç½®åè®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®åè®­ç»ƒå™¨...");
        DeepSeekV3Posttrain posttrain = new DeepSeekV3Posttrain(
            pretrainedModel,
            trainDataset,
            valDataset
        );
        
        // ä¿®å¤ï¼šå¢åŠ è®­ç»ƒè½®æ¬¡ä»¥é€‚åº”å°æ•°æ®é›†
        posttrain.configure(
            5,          // maxEpochs (å¢åŠ è½®æ¬¡)
            5e-5f,      // learningRate (é€‚å½“æé«˜)
            3           // patience (å¢åŠ è€å¿ƒå€¼)
        );
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 5 (å°æ•°æ®é›†éœ€è¦æ›´å¤šè½®æ¬¡)");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 5e-5 (é€‚å½“æé«˜)");
        System.out.println("  âœ“ æ—©åœè€å¿ƒå€¼: 3");
        
        // 4. å¼€å§‹åè®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹åè®­ç»ƒ...");
        System.out.println("-".repeat(80));
        posttrain.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… åè®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ åè®­ç»ƒé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: é€‚åº”ä»»åŠ¡ç‰¹å®šçš„æ¨ç†å’Œç”Ÿæˆ");
        System.out.println("  - ä»»åŠ¡: ä»»åŠ¡æ„ŸçŸ¥çš„æŒ‡ä»¤è·Ÿéš");
        System.out.println("  - æ•°æ®: å¸¦ä»»åŠ¡æ ‡ç­¾çš„æŒ‡ä»¤æ•°æ®");
        System.out.println("  - æŠ€å·§: å°å­¦ä¹ ç‡ + æ—©åœ + ä»»åŠ¡è·¯ç”±");
        System.out.println("  - ç»“æœ: æ¨¡å‹è·å¾—ä»»åŠ¡æ„ŸçŸ¥èƒ½åŠ›");
        
        return pretrainedModel;
    }
    
    /**
     * æ‰§è¡Œä»£ç ç”Ÿæˆä¸“é¡¹åè®­ç»ƒ
     * çº¯ä»£ç ä»»åŠ¡æ•°æ®ï¼Œå¼ºåŒ–MoEä¸“å®¶å¯¹ä»£ç ä»»åŠ¡çš„ç‰¹åŒ–èƒ½åŠ›
     */
    private static DeepSeekV3Model runCodePosttraining(DeepSeekV3Model finetunedModel) throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ’» æ­¥éª¤2B: DeepSeek-V3 ä»£ç ç”Ÿæˆä¸“é¡¹åè®­ç»ƒ");
        System.out.println("=".repeat(80));
        System.out.println("ğŸ’¡ ç›®æ ‡ï¼šå¼ºåŒ–MoEä¸“å®¶å¯¹ä»£ç ä»»åŠ¡çš„ç‰¹åŒ–èƒ½åŠ›");
        System.out.println("ğŸ’¡ ç­–ç•¥ï¼šçº¯ä»£ç ä»»åŠ¡æ•°æ® + æ›´å°å­¦ä¹ ç‡ + æ›´å¤šè®­ç»ƒè½®æ¬¡");
        
        // 1. åŠ è½½ä»£ç ä¸“é¡¹æ•°æ®
        System.out.println("\nğŸ“ åŠ è½½ä»£ç ä¸“é¡¹æ•°æ®...");
        String codeTrainPath = DATA_DIR + "/code_posttrain_train.txt";
        String codeValPath = DATA_DIR + "/code_posttrain_val.txt";
        
        List<String> codeTrainTexts = readFromFile(codeTrainPath);
        List<String> codeValTexts = readFromFile(codeValPath);
        
        System.out.println("  âœ“ ä»£ç ä¸“é¡¹è®­ç»ƒé›†: " + codeTrainTexts.size() + " æ¡");
        System.out.println("  âœ“ ä»£ç ä¸“é¡¹éªŒè¯é›†: " + codeValTexts.size() + " æ¡");
        System.out.println("  âœ“ ä»»åŠ¡ç±»å‹: çº¯CODING (æ‰€æœ‰æ•°æ®éƒ½æ˜¯ä»£ç ä»»åŠ¡)");
        
        // 2. å‡†å¤‡æ•°æ®é›†ï¼ˆçº¯CODINGä»»åŠ¡ï¼‰
        System.out.println("\nğŸ“ å‡†å¤‡ä»£ç ä¸“é¡¹æ•°æ®é›†...");
        DeepSeekV3Config config = finetunedModel.getConfig();
        
        DeepSeekV3Dataset codeTrainDataset = createDatasetFromTexts(
            codeTrainTexts,
            config.getNPositions(),
            2,  // batch size
            config.getVocabSize(),
            true  // ä½¿ç”¨ä»»åŠ¡æ ‡ç­¾ï¼ˆå…¨æ˜¯CODINGï¼‰
        );
        
        DeepSeekV3Dataset codeValDataset = createDatasetFromTexts(
            codeValTexts,
            config.getNPositions(),
            1,  // batch size
            config.getVocabSize(),
            true  // ä½¿ç”¨ä»»åŠ¡æ ‡ç­¾
        );
        
        System.out.println("  âœ“ è®­ç»ƒæ ·æœ¬: " + codeTrainDataset.getSampleCount());
        System.out.println("  âœ“ éªŒè¯æ ·æœ¬: " + codeValDataset.getSampleCount());
        System.out.println("  âœ“ æ”¯æŒè¯­è¨€: Python, Java, JavaScript, C++");
        
        // 3. é…ç½®ä»£ç ä¸“é¡¹åè®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®ä»£ç ä¸“é¡¹åè®­ç»ƒå™¨...");
        DeepSeekV3Posttrain codePosttrain = new DeepSeekV3Posttrain(
            finetunedModel,
            codeTrainDataset,
            codeValDataset
        );
        
        // ä»£ç ä»»åŠ¡ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡å’Œæ›´å¤šçš„è½®æ¬¡
        codePosttrain.configure(
            6,          // maxEpochs (ä»£ç ä»»åŠ¡éœ€è¦æ›´å¤šè½®æ¬¡)
            2e-5f,      // learningRate (é€‚å½“è°ƒæ•´)
            3           // patience
        );
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 6 (ä»£ç ä»»åŠ¡éœ€è¦æ›´å¤šè½®æ¬¡)");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 2e-5 (é€‚å½“è°ƒæ•´)");
        System.out.println("  âœ“ æ—©åœè€å¿ƒå€¼: 3");
        System.out.println("  âœ“ ä¸“å®¶ç‰¹åŒ–: æŒç»­æ¿€æ´»CODINGä¸“å®¶");
        
        // 4. å¼€å§‹ä»£ç ä¸“é¡¹åè®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹ä»£ç ç”Ÿæˆä¸“é¡¹åè®­ç»ƒ...");
        System.out.println("-".repeat(80));
        codePosttrain.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… ä»£ç ä¸“é¡¹åè®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ ä»£ç ä¸“é¡¹åè®­ç»ƒé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: å¼ºåŒ–MoEä¸“å®¶å¯¹ä»£ç ä»»åŠ¡çš„ç‰¹åŒ–");
        System.out.println("  - ä»»åŠ¡: çº¯CODINGä»»åŠ¡çš„æŒ‡ä»¤è·Ÿéš");
        System.out.println("  - æ•°æ®: 60æ¡ä»£ç ç”Ÿæˆé—®ç­” (Python/Java/JS/C++)");
        System.out.println("  - ç‰¹è‰²: æŒç»­æ¿€æ´»åŒä¸€æ‰¹ä¸“å®¶ -> ä¸“å®¶ç‰¹åŒ–èƒ½åŠ›å¢å¼º");
        System.out.println("  - ç»“æœ: æ¨¡å‹è·å¾—æ›´å¼ºçš„ä»£ç ç”Ÿæˆèƒ½åŠ›");
        System.out.println("\nâ„¹ï¸ MoEä¸“å®¶ç‰¹åŒ–è¯´æ˜:");
        System.out.println("  - é€šç”¨åè®­ç»ƒ: CODINGæ•°æ®ä»…å ~20%, ä¸“å®¶æ¿€æ´»æ¨¡å¼æ··åˆ");
        System.out.println("  - ä»£ç ä¸“é¡¹è®­ç»ƒ: CODINGæ•°æ®100%, æŒç»­å¼ºåŒ–ç‰¹å®šä¸“å®¶");
        System.out.println("  - é¢„æœŸæ•ˆæœ: Expert 2,5æˆä¸ºä»£ç ä¸“å®¶, CODINGä»»åŠ¡æ—¶æ¿€æ´»æ¦‚ç‡å¤§å¹…æå‡");
        
        return finetunedModel;
    }
    
    /**
     * æ‰§è¡Œæ¨ç†æµ‹è¯•
     */
    private static void runInference(DeepSeekV3Model model) {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸš€ æ­¥éª¤3: DeepSeek-V3 æ¨ç†ä¸æ–‡æœ¬ç”Ÿæˆ");
        System.out.println("=".repeat(80));
        
        // 1. åˆ›å»ºæ¨ç†å™¨
        System.out.println("\nğŸ“ åˆ›å»ºæ¨ç†å™¨...");
        DeepSeekV3Inference inference = new DeepSeekV3Inference(model);
        inference.setSeed(42);
        System.out.println("  âœ“ æ¨ç†å™¨å‡†å¤‡å®Œæˆ");
        
        // 2. æµ‹è¯•ç”¨ä¾‹
        TestCase[] testCases = {
            new TestCase("Mixture of Experts is", TaskType.GENERAL),
            new TestCase("DeepSeek V3 combines", TaskType.REASONING),
            new TestCase("Python is used for", TaskType.CODING),
            new TestCase("Self attention computes", TaskType.REASONING)
        };
        
        System.out.println("\nğŸ“ æ‰§è¡Œæ–‡æœ¬ç”Ÿæˆæµ‹è¯•...\n");
        
        for (int i = 0; i < testCases.length; i++) {
            TestCase testCase = testCases[i];
            System.out.println("æµ‹è¯• " + (i + 1) + ": \"" + testCase.prompt + "\"");
            System.out.println("ä»»åŠ¡ç±»å‹: " + testCase.taskType);
            System.out.println("-".repeat(80));
            
            try {
                List<Integer> tokens = sharedTokenizer.encode(testCase.prompt);
                int[] promptIds = tokens.stream().mapToInt(Integer::intValue).toArray();
                
                // Greedyè§£ç 
                System.out.println("  ç­–ç•¥1 [Greedyè´ªå©ª]: ");
                var greedyResult = inference.generateGreedy(promptIds, 12, testCase.taskType);
                String greedyText = sharedTokenizer.decode(greedyResult.tokens);
                System.out.println("    â†’ " + greedyText);
                
                // Temperatureé‡‡æ ·
                System.out.println("  ç­–ç•¥2 [Temperature=0.8]: ");
                var tempResult = inference.generateWithTemperature(
                    promptIds, 12, 0.8f, testCase.taskType
                );
                String tempText = sharedTokenizer.decode(tempResult.tokens);
                System.out.println("    â†’ " + tempText);
                
                // Top-Ké‡‡æ ·
                System.out.println("  ç­–ç•¥3 [Top-K=50]: ");
                var topKResult = inference.generateTopK(promptIds, 12, 50, testCase.taskType);
                String topKText = sharedTokenizer.decode(topKResult.tokens);
                System.out.println("    â†’ " + topKText);
                
            } catch (Exception e) {
                System.out.println("  âš  ç”Ÿæˆå¤±è´¥: " + e.getMessage());
            }
            
            System.out.println();
        }
        
        System.out.println("âœ… æ¨ç†æµ‹è¯•å®Œæˆ!");
        System.out.println("\nğŸ’¡ æ¨ç†é˜¶æ®µæ€»ç»“:");
        System.out.println("  - è¾“å…¥: æç¤ºè¯ + ä»»åŠ¡ç±»å‹");
        System.out.println("  - å¤„ç†: ä»»åŠ¡æ„ŸçŸ¥çš„è‡ªå›å½’ç”Ÿæˆ");
        System.out.println("  - è¾“å‡º: ç”Ÿæˆçš„å®Œæ•´æ–‡æœ¬");
        System.out.println("  - ç­–ç•¥: Greedy/Temperature/TopK/TopP");
        System.out.println("  - ç‰¹è‰²: MoEç¨€ç–æ¿€æ´» + ä»»åŠ¡è·¯ç”±");
    }
    
    /**
     * ä»æ–‡æœ¬åˆ›å»ºæ•°æ®é›†
     */
    private static DeepSeekV3Dataset createDatasetFromTexts(
            List<String> texts,
            int maxSeqLength,
            int batchSize,
            int vocabSize,
            boolean useTaskLabels) {
        
        List<int[]> sequences = new ArrayList<>();
        List<TaskType> taskTypes = new ArrayList<>();
        
        for (String text : texts) {
            TaskType taskType = TaskType.GENERAL;
            String cleanText = text;
            
            if (useTaskLabels) {
                // æå–ä»»åŠ¡æ ‡ç­¾
                taskType = extractTaskType(text);
                cleanText = removeTaskLabel(text);
            }
            
            // ç¼–ç æ–‡æœ¬
            List<Integer> tokens = sharedTokenizer.encode(cleanText);
            
            // è½¬æ¢ä¸ºæ•°ç»„
            int[] sequence = tokens.stream().mapToInt(Integer::intValue).toArray();
            
            // æˆªæ–­æˆ–å¡«å……åˆ°maxSeqLength
            // æ˜¾å¼ä½¿ç”¨PAD_TOKEN_IDå¡«å……ï¼Œé¿å…ä¸è¯æ±‡IDå†²çª
            int[] paddedSeq = new int[maxSeqLength];
           Arrays.fill(paddedSeq, SimpleTokenizer.PAD_TOKEN_ID);
            int copyLen = Math.min(sequence.length, maxSeqLength);
            System.arraycopy(sequence, 0, paddedSeq, 0, copyLen);
            
            sequences.add(paddedSeq);
            taskTypes.add(taskType);
        }
        
        return new DeepSeekV3Dataset(sequences, taskTypes, maxSeqLength, batchSize, true);
    }
    
    /**
     * æå–ä»»åŠ¡ç±»å‹æ ‡ç­¾
     */
    private static TaskType extractTaskType(String text) {
        if (text.startsWith("[REASONING]")) return TaskType.REASONING;
        if (text.startsWith("[CODING]")) return TaskType.CODING;
        if (text.startsWith("[MATH]")) return TaskType.MATH;
        if (text.startsWith("[MULTIMODAL]")) return TaskType.MULTIMODAL;
        return TaskType.GENERAL;
    }
    
    /**
     * ç§»é™¤ä»»åŠ¡æ ‡ç­¾
     */
    private static String removeTaskLabel(String text) {
        return text.replaceFirst("^\\[\\w+\\]\\s*", "");
    }
    
    /**
     * ä»æ–‡ä»¶è¯»å–æ–‡æœ¬
     */
    private static List<String> readFromFile(String filePath) throws IOException {
        List<String> lines = new ArrayList<>();
        try (BufferedReader reader = new BufferedReader(new FileReader(filePath))) {
            String line;
            while ((line = reader.readLine()) != null) {
                if (!line.trim().isEmpty()) {
                    lines.add(line);
                }
            }
        }
        return lines;
    }
    
    /**
     * æµ‹è¯•ç”¨ä¾‹ç±»
     */
    private static class TestCase {
        final String prompt;
        final TaskType taskType;
        
        TestCase(String prompt, TaskType taskType) {
            this.prompt = prompt;
            this.taskType = taskType;
        }
    }
    
    /**
     * ç®€å•åˆ†è¯å™¨ï¼ˆç±»ä¼¼GPT1çš„SimpleTokenizerï¼‰
     * æ³¨æ„ï¼šid=0ä¿ç•™ç»™PAD tokenï¼Œé¿å…ä¸è¯æ±‡å†²çª
     */
    static class SimpleTokenizer {
        private final Map<String, Integer> vocab;
        private final Map<Integer, String> reverseVocab;
        private int nextId;
        private boolean frozen;
        
        /** PAD tokençš„IDï¼Œç”¨äºå¡«å…… */
        public static final int PAD_TOKEN_ID = 0;
        
        public SimpleTokenizer() {
            this.vocab = new HashMap<>();
            this.reverseVocab = new HashMap<>();
            // id=0ä¿ç•™ç»™PADï¼Œè¯æ±‡ä»1å¼€å§‹
            this.nextId = 1;
            this.frozen = false;
            // é¢„æ³¨å†ŒPAD token
            this.vocab.put("<PAD>", PAD_TOKEN_ID);
            this.reverseVocab.put(PAD_TOKEN_ID, "<PAD>");
        }
        
        public List<Integer> encode(String text) {
            String[] words = text.toLowerCase()
                .replaceAll("[^a-z0-9\\s]", " ")
                .split("\\s+");
            
            List<Integer> tokens = new ArrayList<>();
            for (String word : words) {
                if (word.isEmpty()) continue;
                
                if (!vocab.containsKey(word)) {
                    if (!frozen) {
                        vocab.put(word, nextId);
                        reverseVocab.put(nextId, word);
                        nextId++;
                    } else {
                        // å†»ç»“åä½¿ç”¨UNK token (ä½¿ç”¨id=1ä½œä¸ºUNKï¼Œé¿å…ä¸PADå†²çª)
                        tokens.add(1);
                        continue;
                    }
                }
                tokens.add(vocab.get(word));
            }
            return tokens;
        }
        
        public String decode(int[] tokens) {
            StringBuilder sb = new StringBuilder();
            for (int token : tokens) {
                // è·³è¿‡PAD token
                if (token == PAD_TOKEN_ID) continue;
                if (reverseVocab.containsKey(token)) {
                    if (sb.length() > 0) sb.append(" ");
                    sb.append(reverseVocab.get(token));
                }
            }
            return sb.toString();
        }
        
        public int getVocabSize() {
            return nextId;
        }
        
        public void freeze() {
            this.frozen = true;
        }
    }
}
