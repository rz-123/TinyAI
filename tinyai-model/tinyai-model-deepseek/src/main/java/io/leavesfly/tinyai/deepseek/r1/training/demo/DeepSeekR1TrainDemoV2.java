package io.leavesfly.tinyai.deepseek.r1.training.demo;

import io.leavesfly.tinyai.deepseek.r1.DeepSeekR1Config;
import io.leavesfly.tinyai.deepseek.r1.DeepSeekR1Model;
import io.leavesfly.tinyai.deepseek.r1.training.*;
import io.leavesfly.tinyai.deepseek.r1.training.dataset.DeepSeekR1Dataset;
import io.leavesfly.tinyai.deepseek.r1.training.dataset.DeepSeekR1RLVRDataset;

import java.io.*;
import java.util.*;

/**
 * DeepSeek-R1å®Œæ•´è®­ç»ƒæ¼”ç¤º V2ç‰ˆæœ¬
 * 
 * æä¾›å®Œæ•´çš„DeepSeek-R1è®­ç»ƒæµç¨‹ç¼–æ’ï¼š
 * 1. æ•°æ®å‡†å¤‡é˜¶æ®µ - ç”Ÿæˆè®­ç»ƒæ•°æ®é›†
 * 2. é¢„è®­ç»ƒé˜¶æ®µ - åŸºç¡€è¯­è¨€å»ºæ¨¡è®­ç»ƒ
 * 3. åè®­ç»ƒé˜¶æ®µ - ä»»åŠ¡ç‰¹å®šå¾®è°ƒ
 * 4. RLHFè®­ç»ƒé˜¶æ®µ - äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ 
 * 5. RLVRè®­ç»ƒé˜¶æ®µ - å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ 
 * 6. æ¨ç†æµ‹è¯•é˜¶æ®µ - å¤šç§ç”Ÿæˆç­–ç•¥æ¼”ç¤º
 * 
 * æ¶æ„ä¼˜åŒ–ï¼š
 * - æ•°æ®ç”Ÿæˆé€»è¾‘æ‹†åˆ†åˆ° {@link DeepSeekR1DatasetGenerator}
 * - åˆ†è¯å·¥å…·æå–åˆ° {@link DeepSeekR1TokenizerUtil}
 * - ä¸»æµç¨‹ä¿æŒç®€æ´ï¼Œèšç„¦è®­ç»ƒæµç¨‹ç¼–æ’
 * 
 * @author leavesfly
 * @version 2.0
 */
public class DeepSeekR1TrainDemoV2 {
    
    private static DeepSeekR1TokenizerUtil sharedTokenizer = new DeepSeekR1TokenizerUtil();
    
    private static final String DATA_DIR = "./data/deepseek_r1_training";
    private static final String CHECKPOINT_DIR = "./checkpoints/deepseek_r1_v2";
    
    public static void main(String[] args) {
        System.out.println("=".repeat(80));
        System.out.println("DeepSeek-R1 å®Œæ•´è®­ç»ƒä¸æ¨ç†æ¼”ç¤º V2");
        System.out.println("é€‚ç”¨äºæ•™å­¦å’Œå­¦ä¹ çš„å°å‹æ•°æ®é›†è®­ç»ƒæ–¹æ¡ˆ");
        System.out.println("ç‰¹è‰²ï¼šæ¨ç†å¢å¼º + è‡ªæˆ‘åæ€ + å¼ºåŒ–å­¦ä¹ å¯¹é½ (RLHF + RLVR)");
        System.out.println("=".repeat(80));
        
        try {
            // æ­¥éª¤0: å‡†å¤‡æ•°æ®é›†æ–‡ä»¶
            DeepSeekR1DatasetGenerator.prepareAllDatasets();
            
            // æ­¥éª¤1: é¢„è®­ç»ƒï¼ˆæ— ç›‘ç£è¯­è¨€å»ºæ¨¡ï¼‰
            DeepSeekR1Model pretrainedModel = runPretraining();
            
            // æ­¥éª¤2: åè®­ç»ƒ/å¾®è°ƒï¼ˆæœ‰ç›‘ç£å­¦ä¹ ï¼‰
            DeepSeekR1Model finetunedModel = runPosttraining(pretrainedModel);
            
            // æ­¥éª¤3: å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆRLHF - R1æ ¸å¿ƒç‰¹è‰²ï¼‰
            DeepSeekR1Model rlhfModel = runRLHFTraining(finetunedModel);
            
            // æ­¥éª¤4: å¼ºåŒ–å­¦ä¹ è®­ç»ƒï¼ˆRLVR - å¯éªŒè¯å¥–åŠ±è®­ç»ƒï¼‰
//            DeepSeekR1Model alignedModel = runRLVRTraining(rlhfModel);
            
            // æ­¥éª¤5: æ¨ç†æµ‹è¯•
            runInference(rlhfModel);
            
            System.out.println("\n" + "=".repeat(80));
            System.out.println("âœ… DeepSeek-R1å®Œæ•´è®­ç»ƒæµç¨‹æ¼”ç¤ºæˆåŠŸ!");
            System.out.println("=".repeat(80));
            
        } catch (Exception e) {
            System.err.println("âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: " + e.getMessage());
            e.printStackTrace();
        }
    }

    // ========== æ­¥éª¤1: é¢„è®­ç»ƒ ==========
    
    /**
     * æ‰§è¡Œé¢„è®­ç»ƒ
     */
    private static DeepSeekR1Model runPretraining() throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ“š æ­¥éª¤1: DeepSeek-R1 é¢„è®­ç»ƒ (Pretrain) - æ— ç›‘ç£è¯­è¨€å»ºæ¨¡");
        System.out.println("=".repeat(80));
        
        // 1. è¯»å–æ‰€æœ‰æ•°æ®ç”¨äºæ„å»ºå®Œæ•´è¯æ±‡è¡¨
        System.out.println("\nğŸ“ åŠ è½½æ‰€æœ‰æ•°æ®ä»¥æ„å»ºè¯æ±‡è¡¨...");
        String pretrainPath = DATA_DIR + "/pretrain.txt";
        String posttrainTrainPath = DATA_DIR + "/posttrain_train.txt";
        String posttrainValPath = DATA_DIR + "/posttrain_val.txt";
        String rlhfPath = DATA_DIR + "/rlhf_train.txt";
        
        List<String> pretrainTexts = DeepSeekR1DatasetGenerator.readFromFile(pretrainPath);
        List<String> posttrainTrainTexts = DeepSeekR1DatasetGenerator.readFromFile(posttrainTrainPath);
        List<String> posttrainValTexts = DeepSeekR1DatasetGenerator.readFromFile(posttrainValPath);
        List<String> rlhfTexts = DeepSeekR1DatasetGenerator.readFromFile(rlhfPath);
        
        System.out.println("  âœ“ é¢„è®­ç»ƒæ•°æ®: " + pretrainTexts.size() + " æ¡");
        System.out.println("  âœ“ åè®­ç»ƒè®­ç»ƒæ•°æ®: " + posttrainTrainTexts.size() + " æ¡");
        System.out.println("  âœ“ åè®­ç»ƒéªŒè¯æ•°æ®: " + posttrainValTexts.size() + " æ¡");
        System.out.println("  âœ“ RLHFè®­ç»ƒæ•°æ®: " + rlhfTexts.size() + " æ¡");
        
        // 2. åŸºäºæ‰€æœ‰æ•°æ®æ„å»ºå®Œæ•´è¯æ±‡è¡¨
        System.out.println("\nğŸ“ æ„å»ºå®Œæ•´è¯æ±‡è¡¨...");
        List<String> allTexts = new ArrayList<>();
        allTexts.addAll(pretrainTexts);
        allTexts.addAll(posttrainTrainTexts);
        allTexts.addAll(posttrainValTexts);
        allTexts.addAll(rlhfTexts);
        
        // éå†æ‰€æœ‰æ–‡æœ¬æ„å»ºè¯æ±‡è¡¨
        for (String text : allTexts) {
            String cleanText = DeepSeekR1TokenizerUtil.removeLabels(text);
            sharedTokenizer.encode(cleanText);
        }
        int vocabSize = sharedTokenizer.getVocabSize();
        
        // å†»ç»“è¯æ±‡è¡¨
        sharedTokenizer.freeze();
        
        System.out.println("  âœ“ å®Œæ•´è¯æ±‡è¡¨å¤§å°: " + vocabSize);
        System.out.println("  âœ“ è¯æ±‡è¡¨å·²å†»ç»“,åç»­ä¸å†å¢åŠ æ–°è¯");
        
        // 3. åˆ›å»ºDeepSeek-R1æ¨¡å‹
        System.out.println("\nğŸ“ åˆ›å»ºDeepSeek-R1æ¨¡å‹...");
        DeepSeekR1Config config = DeepSeekR1Config.createTinyConfig();
        config.setVocabSize(vocabSize);
        config.setMaxReasoningSteps(2);  // å°è§„æ¨¡æ¼”ç¤ºä½¿ç”¨è¾ƒå°‘æ¨ç†æ­¥éª¤
        config.setNLayer(2);  // å‡å°‘å±‚æ•°åŠ é€Ÿè®­ç»ƒ
        
        DeepSeekR1Model model = new DeepSeekR1Model("deepseek-r1-pretrain-v2", config);
        
        System.out.println("  âœ“ æ¨¡å‹é…ç½®: Tiny (æ•™å­¦ä¸“ç”¨)");
        System.out.println("  âœ“ è¯æ±‡è¡¨å¤§å°: " + config.getVocabSize());
        System.out.println("  âœ“ éšè—ç»´åº¦: " + config.getNEmbd());
        System.out.println("  âœ“ å±‚æ•°: " + config.getNLayer());
        System.out.println("  âœ“ æ³¨æ„åŠ›å¤´æ•°: " + config.getNHead());
        System.out.println("  âœ“ æœ€å¤§æ¨ç†æ­¥éª¤: " + config.getMaxReasoningSteps());
        System.out.println("  âœ“ è´¨é‡è¯„åˆ†ç»´åº¦: " + config.getQualityScoreDim());
        
        // 4. å‡†å¤‡æ•°æ®é›†
        System.out.println("\nğŸ“ å‡†å¤‡è®­ç»ƒæ•°æ®é›†...");
        int seqLength = config.getNPositions();
        DeepSeekR1Dataset dataset = createDatasetFromTexts(
            pretrainTexts,
            seqLength,
            4,  // batch size
            config.getVocabSize()
        );
        
        System.out.println("  âœ“ è®­ç»ƒæ ·æœ¬: " + dataset.getSampleCount());
        System.out.println("  âœ“ æ‰¹æ¬¡å¤§å°: 4");
        System.out.println("  âœ“ åºåˆ—é•¿åº¦: " + seqLength);
        
        // 5. é…ç½®è®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®é¢„è®­ç»ƒå™¨...");
        DeepSeekR1Pretrain trainer = new DeepSeekR1Pretrain(model, dataset);
        trainer.configure(
            10,         // maxEpochs
            5e-2f,      // learningRate
            5,          // warmupSteps
            1.0f        // maxGradNorm
        ).setCheckpoint(CHECKPOINT_DIR + "/pretrain", 200);
        trainer.setLogInterval(50);
        trainer.configureParallel(true, 4);
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 10");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 5e-2");
        System.out.println("  âœ“ Warmupæ­¥æ•°: 5");
        System.out.println("  âœ“ å¹¶è¡Œè®­ç»ƒ: å·²å¯ç”¨ (4çº¿ç¨‹)");
        
        // 6. å¼€å§‹è®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹é¢„è®­ç»ƒ...");
        System.out.println("-".repeat(80));
        trainer.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… é¢„è®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ é¢„è®­ç»ƒé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: å­¦ä¹ è¯­è¨€çš„é€šç”¨è¡¨ç¤ºå’Œæ¨ç†åŸºç¡€");
        System.out.println("  - ä»»åŠ¡: å› æœè¯­è¨€å»ºæ¨¡ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ªè¯ï¼‰");
        System.out.println("  - æ•°æ®: å¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬ï¼ˆæ¨ç†ã€æ•°å­¦ã€é€»è¾‘ï¼‰");
        System.out.println("  - R1ç‰¹è‰²: åŒæ—¶å­¦ä¹ æ¨ç†å’Œåæ€èƒ½åŠ›");
        
        return model;
    }
    
    // ========== æ­¥éª¤2: åè®­ç»ƒ/å¾®è°ƒ ==========
    
    /**
     * æ‰§è¡Œåè®­ç»ƒ/å¾®è°ƒ
     */
    private static DeepSeekR1Model runPosttraining(DeepSeekR1Model pretrainedModel) throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ¯ æ­¥éª¤2: DeepSeek-R1 åè®­ç»ƒ/å¾®è°ƒ (Posttrain) - æœ‰ç›‘ç£å­¦ä¹ ");
        System.out.println("=".repeat(80));
        
        // 1. åŠ è½½åè®­ç»ƒæ•°æ®
        System.out.println("\nğŸ“ åŠ è½½åè®­ç»ƒæ•°æ®...");
        String trainPath = DATA_DIR + "/posttrain_train.txt";
        String valPath = DATA_DIR + "/posttrain_val.txt";
        
        List<String> trainTexts = DeepSeekR1DatasetGenerator.readFromFile(trainPath);
        List<String> valTexts = DeepSeekR1DatasetGenerator.readFromFile(valPath);
        
        System.out.println("  âœ“ è®­ç»ƒé›†: " + trainTexts.size() + " æ¡");
        System.out.println("  âœ“ éªŒè¯é›†: " + valTexts.size() + " æ¡");
        
        // 2. å‡†å¤‡æ•°æ®é›†
        System.out.println("\nğŸ“ å‡†å¤‡åè®­ç»ƒæ•°æ®é›†...");
        DeepSeekR1Config config = pretrainedModel.getConfig();
        
        DeepSeekR1Dataset trainDataset = createDatasetFromTexts(
            trainTexts,
            config.getNPositions(),
            2,  // batch size
            config.getVocabSize()
        );
        
        DeepSeekR1Dataset valDataset = createDatasetFromTexts(
            valTexts,
            config.getNPositions(),
            1,  // batch size
            config.getVocabSize()
        );
        
        System.out.println("  âœ“ è®­ç»ƒæ ·æœ¬: " + trainDataset.getSampleCount());
        System.out.println("  âœ“ éªŒè¯æ ·æœ¬: " + valDataset.getSampleCount());
        
        // 3. é…ç½®åè®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®åè®­ç»ƒå™¨...");
        DeepSeekR1Posttrain posttrain = new DeepSeekR1Posttrain(
            pretrainedModel,
            trainDataset,
            valDataset
        );
        
        posttrain.configure(
            3,          // maxEpochs
            1e-3f,      // learningRate
            2           // patience
        );
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 3");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 1e-3");
        System.out.println("  âœ“ æ—©åœè€å¿ƒå€¼: 2");
        
        // 4. å¼€å§‹åè®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹åè®­ç»ƒ...");
        System.out.println("-".repeat(80));
        posttrain.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… åè®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ åè®­ç»ƒé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: ä¼˜åŒ–æ¨ç†è´¨é‡å’Œåæ€èƒ½åŠ›");
        System.out.println("  - ä»»åŠ¡: ä»»åŠ¡ç‰¹å®šçš„æŒ‡ä»¤è·Ÿéš");
        System.out.println("  - æ•°æ®: å¸¦ä»»åŠ¡æ ‡ç­¾çš„æ¨ç†é—®ç­”å¯¹");
        System.out.println("  - æŠ€å·§: å°å­¦ä¹ ç‡ + æ—©åœé˜²æ­¢è¿‡æ‹Ÿåˆ");
        System.out.println("  - R1ç‰¹è‰²: å¢å¼ºé“¾å¼æ¨ç†å’Œè‡ªæˆ‘åæ€");
        
        return pretrainedModel;
    }
    
    // ========== æ­¥éª¤3: å¼ºåŒ–å­¦ä¹ è®­ç»ƒ ==========
    
    /**
     * æ‰§è¡ŒRLHFå¼ºåŒ–å­¦ä¹ è®­ç»ƒ
     */
    private static DeepSeekR1Model runRLHFTraining(DeepSeekR1Model finetunedModel) throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ† æ­¥éª¤3: DeepSeek-R1 RLHFè®­ç»ƒ - äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ");
        System.out.println("=".repeat(80));
        
        // 1. åŠ è½½RLHFæ•°æ®
        System.out.println("\nğŸ“ åŠ è½½RLHFè®­ç»ƒæ•°æ®...");
        String rlhfPath = DATA_DIR + "/rlhf_train.txt";
        List<String> rlhfTexts = DeepSeekR1DatasetGenerator.readFromFile(rlhfPath);
        
        System.out.println("  âœ“ RLHFæ ·æœ¬: " + rlhfTexts.size() + " æ¡");
        
        // 2. å‡†å¤‡RLHFæ•°æ®é›†
        System.out.println("\nğŸ“ å‡†å¤‡RLHFæ•°æ®é›†...");
        DeepSeekR1Config config = finetunedModel.getConfig();
        
        DeepSeekR1Dataset rlhfDataset = createRLHFDatasetFromTexts(
            rlhfTexts,
            config.getNPositions(),
            2,
            config.getVocabSize()
        );
        
        System.out.println("  âœ“ RLHFè®­ç»ƒæ ·æœ¬: " + rlhfDataset.getSampleCount());
        
        // 3. é…ç½®RLHFè®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®RLHFè®­ç»ƒå™¨...");
        DeepSeekR1RLHFTrainer rlhfTrainer = new DeepSeekR1RLHFTrainer(
            finetunedModel,
            rlhfDataset
        );
        
        rlhfTrainer.configure(
            2,          // maxEpochs
            5e-4f,      // learningRate
            1.0f,       // rewardWeight
            0.5f        // qualityWeight
        );
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 2");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 5e-4");
        
        // 4. å¼€å§‹RLHFè®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹RLHFå¼ºåŒ–å­¦ä¹ è®­ç»ƒ...");
        System.out.println("-".repeat(80));
        rlhfTrainer.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… RLHFè®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ RLHFé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: é€šè¿‡äººç±»åé¦ˆå¯¹é½æ¨¡å‹è¡Œä¸º");
        System.out.println("  - ä»»åŠ¡: æœ€å¤§åŒ–äººç±»åå¥½å¥–åŠ±");
        System.out.println("  - æ•°æ®: å¸¦å¥–åŠ±æ ‡æ³¨çš„æ¨ç†æ ·æœ¬");
        System.out.println("  - R1ç‰¹è‰²: å¹³è¡¡äººç±»åé¦ˆä¸æ¨¡å‹è‡ªè¯„è´¨é‡");
        
        return finetunedModel;
    }
    
    /**
     * æ‰§è¡ŒRLVRè®­ç»ƒï¼ˆå¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ï¼‰
     */
    private static DeepSeekR1Model runRLVRTraining(DeepSeekR1Model rlhfModel) throws IOException {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸ† æ­¥éª¤4: DeepSeek-R1 RLVRè®­ç»ƒ - å¯éªŒè¯å¥–åŠ±å¼ºåŒ–å­¦ä¹ ");
        System.out.println("=".repeat(80));
        
        // 1. åŠ è½½RLVRæ•°æ®
        System.out.println("\nğŸ“ åŠ è½½RLVRè®­ç»ƒæ•°æ®...");
        String rlvrPath = DATA_DIR + "/rlvr_train.txt";
        List<String> rlvrTexts = DeepSeekR1DatasetGenerator.readFromFile(rlvrPath);
        
        System.out.println("  âœ“ RLVRæ ·æœ¬: " + rlvrTexts.size() + " æ¡");
        
        // 2. å‡†å¤‡RLVRæ•°æ®é›†
        System.out.println("\nğŸ“ å‡†å¤‡RLVRæ•°æ®é›†...");
        DeepSeekR1Config config = rlhfModel.getConfig();
        
        DeepSeekR1RLVRDataset rlvrDataset = createRLVRDatasetFromTexts(
            rlvrTexts,
            config.getNPositions(),
            2,
            config.getVocabSize()
        );
        
        System.out.println("  âœ“ RLVRè®­ç»ƒæ ·æœ¬: " + rlvrDataset.getSampleCount());
        
        // 3. é…ç½®RLVRè®­ç»ƒå™¨
        System.out.println("\nğŸ“ é…ç½®RLVRè®­ç»ƒå™¨...");
        DeepSeekR1RLVRTrainer rlvrTrainer = new DeepSeekR1RLVRTrainer(
            rlhfModel,
            rlvrDataset
        );
        
        rlvrTrainer.configure(
            50,         // maxEpochs (å¢åŠ è®­ç»ƒè½®æ¬¡ä»¥å……åˆ†å­¦ä¹ )
            0.05f,      // learningRate (é™ä½å­¦ä¹ ç‡æé«˜ç¨³å®šæ€§)
            0.7f,       // correctnessWeight
            0.2f,       // reasoningQualityWeight
            0.1f        // verificationWeight
        );
        
        System.out.println("  âœ“ æœ€å¤§è½®æ¬¡: 50");
        System.out.println("  âœ“ å­¦ä¹ ç‡: 0.05");
        
        // 4. å¼€å§‹RLVRè®­ç»ƒ
        System.out.println("\nğŸ“ å¼€å§‹RLVRå¼ºåŒ–å­¦ä¹ è®­ç»ƒ...");
        System.out.println("-".repeat(80));
        rlvrTrainer.train();
        System.out.println("-".repeat(80));
        
        System.out.println("\nâœ… RLVRè®­ç»ƒå®Œæˆ!");
        System.out.println("\nğŸ’¡ RLVRé˜¶æ®µæ€»ç»“:");
        System.out.println("  - ç›®æ ‡: é€šè¿‡å¯éªŒè¯æ ‡å‡†ä¼˜åŒ–æ­£ç¡®æ€§");
        System.out.println("  - ä»»åŠ¡: æœ€å¤§åŒ–äºŒå€¼éªŒè¯å¥–åŠ±(0æˆ–1)");
        System.out.println("  - æ•°æ®: å¸¦æ ‡å‡†ç­”æ¡ˆçš„å¯éªŒè¯é—®é¢˜");
        System.out.println("  - ä¼˜åŠ¿: RLHF + RLVR ç»“åˆæå‡æ¨¡å‹èƒ½åŠ›");
        
        return rlhfModel;
    }
    
    // ========== æ­¥éª¤5: æ¨ç†æµ‹è¯• ==========
    
    /**
     * æ‰§è¡Œæ¨ç†æµ‹è¯•
     */
    private static void runInference(DeepSeekR1Model model) {
        System.out.println("\n" + "=".repeat(80));
        System.out.println("ğŸš€ æ­¥éª¤5: DeepSeek-R1 æ¨ç†ä¸æ–‡æœ¬ç”Ÿæˆ");
        System.out.println("=".repeat(80));
        
        // 1. åˆ›å»ºæ¨ç†å™¨
        System.out.println("\nğŸ“ åˆ›å»ºæ¨ç†å™¨...");
        DeepSeekR1Inference inference = new DeepSeekR1Inference(model);
        System.out.println("  âœ“ æ¨ç†å™¨å‡†å¤‡å®Œæˆ");
        
        // 2. æµ‹è¯•ç”¨ä¾‹
        String[] prompts = {
            "Reasoning requires",
            "Mathematics is",
            "Logic helps",
            "Self reflection"
        };
        
        System.out.println("\nğŸ“ æ‰§è¡Œæ–‡æœ¬ç”Ÿæˆæµ‹è¯•ï¼ˆå¸¦æ¨ç†è¿‡ç¨‹ï¼‰...\n");
        
        for (int i = 0; i < prompts.length; i++) {
            String prompt = prompts[i];
            System.out.println("æµ‹è¯• " + (i + 1) + ": \"" + prompt + "\"");
            System.out.println("-".repeat(80));
            
            try {
                List<Integer> tokens = sharedTokenizer.encode(prompt);
                int[] promptIds = tokens.stream().mapToInt(Integer::intValue).toArray();
                
                // Greedyè§£ç 
                System.out.println("  ç­–ç•¥1 [Greedyè´ªå©ªè§£ç ]: ");
                DeepSeekR1Inference.GenerationResult greedyResult = 
                    inference.generateGreedy(promptIds, 10);
                String greedyText = sharedTokenizer.decode(greedyResult.tokens);
                System.out.println("    â†’ " + greedyText);
                // è°ƒè¯•ï¼šæ˜¾ç¤ºç”Ÿæˆçš„tokenè¯¦æƒ…
                System.out.print("    Token IDs: ");
                for (int t : greedyResult.tokens) System.out.print(t + " ");
                System.out.println("(å…±" + greedyResult.tokens.length + "ä¸ª)");
                
                // æ‰“å°æ¨ç†ç»Ÿè®¡
                if (!greedyResult.reasoningSteps.isEmpty()) {
                    DeepSeekR1Inference.ReasoningStep lastStep = 
                        greedyResult.reasoningSteps.get(greedyResult.reasoningSteps.size() - 1);
                    System.out.printf("    æ¨ç†æ­¥éª¤: %d, ç½®ä¿¡åº¦: %.4f, è´¨é‡åˆ†: %.4f%n",
                        lastStep.reasoningSteps, lastStep.confidence, lastStep.qualityScore);
                }
                
                // Temperatureé‡‡æ ·
                System.out.println("  ç­–ç•¥2 [Temperature=0.8]: ");
                DeepSeekR1Inference.GenerationResult tempResult = 
                    inference.generateWithTemperature(promptIds, 10, 0.8f);
                String tempText = sharedTokenizer.decode(tempResult.tokens);
                System.out.println("    â†’ " + tempText);
                
            } catch (Exception e) {
                System.out.println("  âš  ç”Ÿæˆå¤±è´¥: " + e.getMessage());
            }
            
            System.out.println();
        }
        
        System.out.println("âœ… æ¨ç†æµ‹è¯•å®Œæˆ!");
        System.out.println("\nğŸ’¡ æ¨ç†é˜¶æ®µæ€»ç»“:");
        System.out.println("  - è¾“å…¥: æç¤ºè¯");
        System.out.println("  - å¤„ç†: æ¨ç†å¢å¼ºçš„è‡ªå›å½’ç”Ÿæˆ");
        System.out.println("  - è¾“å‡º: ç”Ÿæˆæ–‡æœ¬ + æ¨ç†è¿‡ç¨‹");
        System.out.println("  - ç­–ç•¥: Greedy/Temperatureé‡‡æ ·");
        System.out.println("  - R1ç‰¹è‰²: æ¯ä¸ªç”Ÿæˆæ­¥éª¤éƒ½æœ‰æ¨ç†ç½®ä¿¡åº¦å’Œè´¨é‡è¯„åˆ†");
    }
    
    // ========== è¾…åŠ©æ–¹æ³• ==========
    
    /**
     * ä»æ–‡æœ¬åˆ›å»ºæ•°æ®é›†
     */
    private static DeepSeekR1Dataset createDatasetFromTexts(
            List<String> texts,
            int maxSeqLength,
            int batchSize,
            int vocabSize) {
        
        List<int[]> sequences = new ArrayList<>();
        
        for (String text : texts) {
            String cleanText = DeepSeekR1TokenizerUtil.removeLabels(text);
            
            // ç¼–ç æ–‡æœ¬
            List<Integer> tokens = sharedTokenizer.encode(cleanText);
            
            // è½¬æ¢ä¸ºæ•°ç»„
            int[] sequence = tokens.stream().mapToInt(Integer::intValue).toArray();
            
            // æˆªæ–­æˆ–å¡«å……åˆ°maxSeqLength
            int[] paddedSeq = new int[maxSeqLength];
            Arrays.fill(paddedSeq, DeepSeekR1TokenizerUtil.PAD_TOKEN_ID);
            int copyLen = Math.min(sequence.length, maxSeqLength);
            System.arraycopy(sequence, 0, paddedSeq, 0, copyLen);
            
            sequences.add(paddedSeq);
        }
        
        return new DeepSeekR1Dataset(sequences, maxSeqLength, batchSize, true);
    }
    
    /**
     * ä»RLHFæ–‡æœ¬åˆ›å»ºæ•°æ®é›†ï¼ˆåŒ…å«å¥–åŠ±ï¼‰
     */
    private static DeepSeekR1Dataset createRLHFDatasetFromTexts(
            List<String> texts,
            int maxSeqLength,
            int batchSize,
            int vocabSize) {
        
        List<int[]> sequences = new ArrayList<>();
        List<String> reasoning = new ArrayList<>();
        List<Float> rewards = new ArrayList<>();
        
        for (String text : texts) {
            // æå–å¥–åŠ±å€¼
            float reward = DeepSeekR1TokenizerUtil.extractReward(text);
            String cleanText = DeepSeekR1TokenizerUtil.removeLabels(text);
            
            // ç¼–ç æ–‡æœ¬
            List<Integer> tokens = sharedTokenizer.encode(cleanText);
            
            // è½¬æ¢ä¸ºæ•°ç»„
            int[] sequence = tokens.stream().mapToInt(Integer::intValue).toArray();
            
            // æˆªæ–­æˆ–å¡«å……
            int[] paddedSeq = new int[maxSeqLength];
            Arrays.fill(paddedSeq, DeepSeekR1TokenizerUtil.PAD_TOKEN_ID);
            int copyLen = Math.min(sequence.length, maxSeqLength);
            System.arraycopy(sequence, 0, paddedSeq, 0, copyLen);
            
            sequences.add(paddedSeq);
            reasoning.add(cleanText);
            rewards.add(reward);
        }
        
        return new DeepSeekR1Dataset(sequences, reasoning, rewards, 
                                     maxSeqLength, batchSize, true);
    }
    
    /**
     * ä»RLVRæ–‡æœ¬åˆ›å»ºæ•°æ®é›†ï¼ˆåŒ…å«éªŒè¯ç±»å‹å’Œæ ‡å‡†ç­”æ¡ˆï¼‰
     */
    private static DeepSeekR1RLVRDataset createRLVRDatasetFromTexts(
            List<String> texts,
            int maxSeqLength,
            int batchSize,
            int vocabSize) {
        
        DeepSeekR1RLVRDataset dataset = new DeepSeekR1RLVRDataset(
            batchSize, maxSeqLength, vocabSize
        );
        
        for (String text : texts) {
            // è§£ææ ¼å¼: [TYPE:verifier_type] Question | GroundTruth
            String verifierType = DeepSeekR1TokenizerUtil.extractVerifierType(text);
            String cleanText = DeepSeekR1TokenizerUtil.removeLabels(text);
            
            // åˆ†ç¦»é—®é¢˜å’Œç­”æ¡ˆ
            String[] parts = cleanText.split("\\|");
            if (parts.length >= 2) {
                String question = parts[0].trim();
                String groundTruth = parts[1].trim();
                
                // ç¼–ç é—®é¢˜
                List<Integer> tokens = sharedTokenizer.encode(question);
                
                // è½¬æ¢ä¸ºæ•°ç»„
                float[] tokenIds = new float[maxSeqLength];
                Arrays.fill(tokenIds, (float) DeepSeekR1TokenizerUtil.PAD_TOKEN_ID);
                int copyLen = Math.min(tokens.size(), maxSeqLength);
                for (int i = 0; i < copyLen; i++) {
                    tokenIds[i] = tokens.get(i).floatValue();
                }
                
                // æ·»åŠ åˆ°æ•°æ®é›†
                dataset.addSample(tokenIds, groundTruth, verifierType);
            }
        }
        
        return dataset;
    }
}
