# GPT-1 æ¨¡å‹å®ç°

åŸºäºTinyAIæ¡†æ¶**å®Œå…¨ç‹¬ç«‹**å®ç°çš„GPT-1è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨è§£ç å™¨-only Transformeræ¶æ„ã€‚100%åŸºäº**nnet v2 API**ï¼Œå¼€åˆ›äº†"é¢„è®­ç»ƒ+å¾®è°ƒ"èŒƒå¼ï¼Œæ˜¯GPTç³»åˆ—çš„å¥ åŸºä¹‹ä½œã€‚æä¾›ä»é¢„è®­ç»ƒåˆ°æ¨ç†çš„å®Œæ•´å®ç°ã€‚

## âœ¨ æ ¸å¿ƒç‰¹ç‚¹

- âœ… **å®Œå…¨ç‹¬ç«‹å®ç°** - é›¶ä¾èµ–GPT-2/GPT-3ï¼Œå®Œå…¨ç‹¬ç«‹çš„æ¨¡å—
- âœ… **100% V2 API** - å…¨éƒ¨åŸºäºnnet v2ç»„ä»¶ï¼ˆModuleã€Linearã€LayerNormç­‰ï¼‰
- âœ… **Post-LayerNormæ¶æ„** - éµå¾ªåŸå§‹Transformerè®¾è®¡ï¼Œåœ¨å­å±‚ä¹‹ååº”ç”¨å½’ä¸€åŒ–
- âœ… **å®Œæ•´è®­ç»ƒæµç¨‹** - é¢„è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ä¸‰é˜¶æ®µå®Œæ•´å®ç°
- âœ… **å¤šç§æ¨ç†ç­–ç•¥** - 5ç§ç”Ÿæˆç­–ç•¥ï¼šGreedyã€Temperatureã€Top-Kã€Top-Pã€Beam Search
- âœ… **å®Œæ•´æµ‹è¯•è¦†ç›–** - 165ä¸ªå•å…ƒæµ‹è¯•ï¼Œ2686è¡Œæµ‹è¯•ä»£ç 

## ğŸ“ æ–‡ä»¶ç»“æ„

```
tinyai-model-gpt/src/main/java/io/leavesfly/tinyai/gpt1/
â”œâ”€â”€ GPT1Config.java              # GPT-1é…ç½®ç±»ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼Œ359è¡Œï¼‰
â”œâ”€â”€ GPT1TokenEmbedding.java      # TokenåµŒå…¥å±‚ï¼ˆV2 Moduleï¼Œ130è¡Œï¼‰
â”œâ”€â”€ GPT1TransformerBlock.java    # Transformerå—ï¼ˆV2 Moduleï¼Œ103è¡Œï¼‰
â”œâ”€â”€ GPT1MainBlock.java           # ä¸»ä½“å—ï¼ˆV2 Moduleï¼Œ139è¡Œï¼‰
â”œâ”€â”€ GPT1Model.java               # æ¨¡å‹ç±»ï¼ˆç»§æ‰¿Modelï¼Œ149è¡Œï¼‰
â”œâ”€â”€ GPT1Demo.java                # åŸºç¡€æ¼”ç¤ºç¨‹åºï¼ˆ135è¡Œï¼‰
â””â”€â”€ training/                    # è®­ç»ƒå’Œæ¨ç†æ¨¡å—
    â”œâ”€â”€ GPT1Dataset.java         # æ•°æ®é›†å¤„ç†ï¼ˆ340è¡Œï¼‰
    â”œâ”€â”€ GPT1Pretrain.java        # é¢„è®­ç»ƒå™¨ï¼ˆ382è¡Œï¼‰
    â”œâ”€â”€ GPT1Finetune.java        # å¾®è°ƒè®­ç»ƒå™¨ï¼ˆ397è¡Œï¼‰
    â”œâ”€â”€ GPT1Inference.java       # æ¨ç†å¼•æ“ï¼ˆ460è¡Œï¼‰
    â””â”€â”€ GPT1TrainDemo.java       # è®­ç»ƒæ¼”ç¤ºï¼ˆ276è¡Œï¼‰

tinyai-model-gpt/src/test/java/io/leavesfly/tinyai/gpt1/
â”œâ”€â”€ GPT1ConfigTest.java          # é…ç½®æµ‹è¯•ï¼ˆ468è¡Œï¼‰
â”œâ”€â”€ GPT1ModelTest.java           # æ¨¡å‹æµ‹è¯•ï¼ˆ448è¡Œï¼‰
â””â”€â”€ training/
    â”œâ”€â”€ GPT1DatasetTest.java     # æ•°æ®é›†æµ‹è¯•ï¼ˆ472è¡Œï¼‰
    â”œâ”€â”€ GPT1PretrainTest.java    # é¢„è®­ç»ƒæµ‹è¯•ï¼ˆ380è¡Œï¼‰
    â”œâ”€â”€ GPT1FinetuneTest.java    # å¾®è°ƒæµ‹è¯•ï¼ˆ492è¡Œï¼‰
    â””â”€â”€ GPT1InferenceTest.java   # æ¨ç†æµ‹è¯•ï¼ˆ426è¡Œï¼‰
```

**æ€»ä»£ç é‡**: 
- ä¸»ä»£ç ï¼š~2,370è¡Œï¼ˆåŒ…å«è®­ç»ƒå’Œæ¨ç†ï¼‰
- æµ‹è¯•ä»£ç ï¼š~2,686è¡Œï¼Œ165ä¸ªæµ‹è¯•æ–¹æ³•
- å…¨éƒ¨åŸºäºV2 APIï¼Œé›¶ä¾èµ–GPT-2/GPT-3

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### 1. å®Œå…¨ç‹¬ç«‹çš„V2æ¶æ„

**GPT1Config** - å®Œå…¨ç‹¬ç«‹é…ç½®ç±»ï¼ˆ359è¡Œï¼‰
- âœ… é›¶ç»§æ‰¿å…¶ä»–GPTé…ç½®ï¼Œæ‰€æœ‰å‚æ•°ç‹¬ç«‹å®šä¹‰
- âœ… åŸºç¡€é…ç½®ï¼švocabSizeã€nEmbdã€nLayerã€nHeadç­‰
- âœ… Dropouté…ç½®ï¼šresidPdropã€embdPdropã€attnPdrop
- âœ… GPT-1ç‰¹æœ‰ï¼šPost-LayerNormæ¶æ„ï¼Œåºåˆ—é•¿åº¦512
- âœ… å®Œæ•´çš„Getter/Setterå’Œvalidate()æ–¹æ³•
- âœ… ä¸‰ç§é¢„è®¾é…ç½®ï¼šTinyã€Smallã€Standard

**GPT1TokenEmbedding** - ç‹¬ç«‹TokenåµŒå…¥å±‚ï¼ˆV2 Moduleï¼‰
- âœ… å®Œå…¨åŸºäºV2 Moduleå®ç°
- âœ… ä½¿ç”¨V2 Parameterç®¡ç†åµŒå…¥çŸ©é˜µ
- âœ… TokenåµŒå…¥ + ä½ç½®åµŒå…¥ + Dropout
- âœ… æ”¯æŒä»»æ„è¯æ±‡è¡¨å¤§å°å’Œåºåˆ—é•¿åº¦

**GPT1TransformerBlock** - Post-LayerNorm Transformerå—ï¼ˆV2 Moduleï¼‰
- âœ… 100%ä½¿ç”¨V2ç»„ä»¶ï¼šLayerNormã€MultiHeadAttentionã€Linearã€GELUã€Dropout
- âœ… Post-LayerNormæ¶æ„ï¼šå…ˆè®¡ç®—å†å½’ä¸€åŒ–
- âœ… å› æœæ©ç è‡ªåŠ¨ç”Ÿæˆ
- âœ… æ®‹å·®è¿æ¥ç¡®ä¿æ¢¯åº¦æµåŠ¨

**GPT1MainBlock** - ä¸»ä½“å—ï¼ˆV2 Moduleï¼‰
- âœ… ç»§æ‰¿V2 Moduleè€Œév1 Block
- âœ… ç»„è£…å®Œæ•´æ¨¡å‹ï¼šTokenåµŒå…¥ â†’ NÃ—Transformer â†’ LayerNorm â†’ è¾“å‡ºæŠ•å½±
- âœ… æ‰€æœ‰å­æ¨¡å—é€šè¿‡registerModule()æ³¨å†Œ
- âœ… å®Œæ•´çš„æ¶æ„ä¿¡æ¯è¾“å‡º

### 2. å®Œæ•´è®­ç»ƒå’Œæ¨ç†æµç¨‹

**GPT1Pretrain** - é¢„è®­ç»ƒå™¨ï¼ˆ382è¡Œï¼‰
- âœ… å› æœè¯­è¨€å»ºæ¨¡ï¼ˆCausal Language Modelingï¼‰
- âœ… å­¦ä¹ ç‡warmup + cosineè¡°å‡
- âœ… æ¢¯åº¦è£å‰ªï¼ˆmax_norm=1.0ï¼‰
- âœ… æ£€æŸ¥ç‚¹ä¿å­˜å’Œæ¢å¤
- âœ… è®­ç»ƒæŒ‡æ ‡è®°å½•

**GPT1Finetune** - å¾®è°ƒè®­ç»ƒå™¨ï¼ˆ397è¡Œï¼‰
- âœ… ä»»åŠ¡ç‰¹å®šå¾®è°ƒ
- âœ… æ›´å°çš„å­¦ä¹ ç‡ï¼ˆ2.5e-5ï¼‰
- âœ… æ—©åœæœºåˆ¶ï¼ˆpatience-basedï¼‰
- âœ… éªŒè¯é›†è¯„ä¼°
- âœ… æœ€ä½³æ¨¡å‹ä¿å­˜

**GPT1Inference** - æ¨ç†å¼•æ“ï¼ˆ460è¡Œï¼‰
- âœ… 5ç§æ–‡æœ¬ç”Ÿæˆç­–ç•¥
- âœ… Greedy Decodingï¼ˆç¡®å®šæ€§ï¼‰
- âœ… Temperature Samplingï¼ˆå¯æ§éšæœºæ€§ï¼‰
- âœ… Top-K Samplingï¼ˆé¿å…ä½æ¦‚ç‡tokenï¼‰
- âœ… Top-P/Nucleus Samplingï¼ˆåŠ¨æ€å€™é€‰é›†ï¼‰
- âœ… Beam Searchï¼ˆå…¨å±€æœ€ä¼˜ï¼‰

**GPT1Dataset** - æ•°æ®é›†å¤„ç†ï¼ˆ340è¡Œï¼‰
- âœ… æ–‡æœ¬åŠ è½½å’Œåˆ†è¯
- âœ… æ‰¹æ¬¡ç”Ÿæˆï¼ˆæ”¯æŒshuffleï¼‰
- âœ… å› æœè¯­è¨€å»ºæ¨¡çš„è¾“å…¥-ç›®æ ‡å¯¹ç”Ÿæˆ
- âœ… ç®€åŒ–çš„Tokenizerå®ç°ï¼ˆå¯æ›¿æ¢ä¸ºBPEï¼‰

### 3. å¤šè§„æ¨¡æ¨¡å‹æ”¯æŒ
- **Tinyé…ç½®**: 256ç»´, 6å±‚, 8å¤´ (~10Må‚æ•°ï¼Œå¿«é€Ÿæµ‹è¯•)
- **Smallé…ç½®**: 512ç»´, 8å±‚, 8å¤´ (~45Må‚æ•°ï¼Œå­¦ä¹ å®éªŒ)
- **Standardé…ç½®**: 768ç»´, 12å±‚, 12å¤´ (~117Må‚æ•°ï¼ŒåŸè®ºæ–‡é…ç½®)

### 4. GPT-1æ¶æ„ç‰¹ç‚¹
- **Post-LayerNormç»“æ„**: å­å±‚è¾“å‡ºååº”ç”¨å±‚å½’ä¸€åŒ–
- **æ ‡å‡†Transformerè§£ç å™¨**: å› æœæ©ç çš„è‡ªæ³¨æ„åŠ›
- **åºåˆ—é•¿åº¦**: 512ï¼ˆç›¸æ¯”GPT-2/3çš„1024/2048è¾ƒçŸ­ï¼‰
- **å‚æ•°è§„æ¨¡**: 117Mï¼ˆæ ‡å‡†é…ç½®ï¼‰

## ğŸ—ï¸ ç½‘ç»œæ¶æ„å›¾

### GPT-1æ•´ä½“æ¶æ„ï¼ˆå®Œå…¨ç‹¬ç«‹å®ç°ï¼‰
```mermaid
graph TB
    Input["Token IDs<br/>(batch_size, seq_len)"] --> TokenEmbed["GPT1TokenEmbedding<br/>V2 Module<br/>Token+ä½ç½®åµŒå…¥"]
    TokenEmbed --> TransBlock1["GPT1TransformerBlock 1<br/>Post-LayerNorm"]
    TransBlock1 --> TransBlock2["GPT1TransformerBlock 2<br/>Attention + FFN"]
    TransBlock2 --> TransBlockN["...<br/>GPT1TransformerBlock N<br/>(æœ€å¤š12å±‚)"]
    TransBlockN --> FinalLN["æœ€ç»ˆå±‚å½’ä¸€åŒ–<br/>LayerNorm (V2)"]
    FinalLN --> OutputProj["è¾“å‡ºæŠ•å½±<br/>Linear (V2)"]
    OutputProj --> Output["Logits<br/>(batch_size, seq_len, vocab_size)"]
```

### GPT1TransformerBlockæ¶æ„ï¼ˆV2 Moduleï¼ŒPost-LayerNormï¼‰
```mermaid
graph TD
    BlockInput["è¾“å…¥<br/>(batch_size, seq_len, n_embd)"] --> MHA["MultiHeadAttention (V2)<br/>å¸¦å› æœæ©ç "]
    MHA --> AttnDropout["Dropout (V2)"]
    AttnDropout --> Add1["æ®‹å·®è¿æ¥<br/>input + attn"]
    BlockInput --> Add1
    Add1 --> LN1["LayerNorm 1 (V2)<br/>Post-LN"]
    
    LN1 --> Linear1["Linear (V2)<br/>å‡ç»´åˆ°nInner"]
    Linear1 --> GELU["GELU (V2)"]
    GELU --> Linear2["Linear (V2)<br/>é™ç»´åˆ°nEmbd"]
    Linear2 --> MLPDropout["Dropout (V2)"]
    MLPDropout --> Add2["æ®‹å·®è¿æ¥<br/>x + mlp"]
    LN1 --> Add2
    Add2 --> LN2["LayerNorm 2 (V2)<br/>Post-LN"]
    
    LN2 --> BlockOutput["è¾“å‡º<br/>(batch_size, seq_len, n_embd)"]
```

### V2ç»„ä»¶ä¾èµ–å›¾
```mermaid
graph TD
    GPT1Model["GPT1Model<br/>(ç»§æ‰¿Model)"] --> GPT1MainBlock
    GPT1MainBlock["GPT1MainBlock<br/>(V2 Module)"] --> GPT1TokenEmbedding
    GPT1MainBlock --> TransformerList["N Ã— GPT1TransformerBlock"]
    GPT1MainBlock --> FinalLN["LayerNorm (V2)"]
    GPT1MainBlock --> OutputLinear["Linear (V2)"]
    
    GPT1TokenEmbedding["GPT1TokenEmbedding<br/>(V2 Module)"] --> TokenParam["Parameter (V2)<br/>TokenåµŒå…¥çŸ©é˜µ"]
    GPT1TokenEmbedding --> PosParam["Parameter (V2)<br/>ä½ç½®åµŒå…¥çŸ©é˜µ"]
    GPT1TokenEmbedding --> EmbedDropout["Dropout (V2)"]
    
    TransformerList --> GPT1TransformerBlock
    GPT1TransformerBlock["GPT1TransformerBlock<br/>(V2 Module)"] --> MHA["MultiHeadAttention (V2)"]
    GPT1TransformerBlock --> LN1["LayerNorm (V2)"]
    GPT1TransformerBlock --> LN2["LayerNorm (V2)"]
    GPT1TransformerBlock --> Linear1["Linear (V2)"]
    GPT1TransformerBlock --> GELU["GELU (V2)"]
    GPT1TransformerBlock --> Linear2["Linear (V2)"]
    GPT1TransformerBlock --> Dropout1["Dropout (V2)"]
    GPT1TransformerBlock --> Dropout2["Dropout (V2)"]
    
    GPT1Config["GPT1Config<br/>(å®Œå…¨ç‹¬ç«‹)"] -.é…ç½®.-> GPT1Model
```

### GPT-1 vs GPT-2/3 æ¶æ„å¯¹æ¯”
```mermaid
graph LR
    subgraph GPT1["GPT-1 (Post-LN)"]
        G1Input["Input"] --> G1Attn["Attention"]
        G1Attn --> G1Add1["+ Input"]
        G1Add1 --> G1LN1["LayerNorm"]
        G1LN1 --> G1FFN["FFN"]
        G1FFN --> G1Add2["+ x"]
        G1Add2 --> G1LN2["LayerNorm"]
    end
    
    subgraph GPT2["GPT-2/3 (Pre-LN)"]
        G2Input["Input"] --> G2LN1["LayerNorm"]
        G2LN1 --> G2Attn["Attention"]
        G2Attn --> G2Add1["+ Input"]
        G2Add1 --> G2LN2["LayerNorm"]
        G2LN2 --> G2FFN["FFN"]
        G2FFN --> G2Add2["+ x"]
    end
```

### è®­ç»ƒæµç¨‹å›¾
```mermaid
graph TB
    Start["å¼€å§‹"] --> Pretrain["é¢„è®­ç»ƒé˜¶æ®µ<br/>GPT1Pretrain"]
    Pretrain --> PreData["å¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬<br/>å› æœè¯­è¨€å»ºæ¨¡"]
    PreData --> PreConfig["å­¦ä¹ ç‡: 2.5e-4<br/>Warmup + Cosine Decay<br/>æ¢¯åº¦è£å‰ª: 1.0"]
    PreConfig --> PreModel["é¢„è®­ç»ƒæ¨¡å‹<br/>checkpoints/pretrain"]
    
    PreModel --> Finetune["å¾®è°ƒé˜¶æ®µ<br/>GPT1Finetune"]
    Finetune --> FineData["ä»»åŠ¡ç‰¹å®šæ•°æ®<br/>è®­ç»ƒé›† + éªŒè¯é›†"]
    FineData --> FineConfig["å­¦ä¹ ç‡: 2.5e-5<br/>æ—©åœæœºåˆ¶<br/>éªŒè¯é›†è¯„ä¼°"]
    FineConfig --> FineModel["å¾®è°ƒæ¨¡å‹<br/>checkpoints/finetune"]
    
    FineModel --> Inference["æ¨ç†é˜¶æ®µ<br/>GPT1Inference"]
    Inference --> GenStrategy{"é€‰æ‹©ç”Ÿæˆç­–ç•¥"}
    GenStrategy --> Greedy["Greedy Decoding<br/>ç¡®å®šæ€§è¾“å‡º"]
    GenStrategy --> Temp["Temperature<br/>å¯æ§éšæœºæ€§"]
    GenStrategy --> TopK["Top-K Sampling<br/>é«˜è´¨é‡é‡‡æ ·"]
    GenStrategy --> TopP["Top-P Sampling<br/>åŠ¨æ€å€™é€‰é›†"]
    GenStrategy --> Beam["Beam Search<br/>å…¨å±€æœ€ä¼˜"]
    
    Greedy --> Output["ç”Ÿæˆæ–‡æœ¬"]
    Temp --> Output
    TopK --> Output
    TopP --> Output
    Beam --> Output
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```java
import io.leavesfly.tinyai.gpt1.*;
import io.leavesfly.tinyai.func.Variable;
import io.leavesfly.tinyai.ndarr.NdArray;
import io.leavesfly.tinyai.ndarr.Shape;

// 1. åˆ›å»ºä¸åŒè§„æ¨¡çš„GPT-1æ¨¡å‹
GPT1Model tinyModel = GPT1Model.createTinyModel("gpt1-tiny");          // ~10Må‚æ•°
GPT1Model smallModel = GPT1Model.createSmallModel("gpt1-small");       // ~45Må‚æ•°
GPT1Model standardModel = GPT1Model.createStandardModel("gpt1-std");   // ~117Må‚æ•°

// 2. æ‰“å°æ¨¡å‹ä¿¡æ¯
standardModel.printModelInfo();

// 3. æ ‡å‡†å‰å‘ä¼ æ’­
NdArray tokenIds = NdArray.of(Shape.of(2, 20)); // (batch_size=2, seq_len=20)
Variable output = standardModel.forward(new Variable(tokenIds));
System.out.println("è¾“å‡ºå½¢çŠ¶: " + output.getValue().getShape()); // (2, 20, 40478)

// 4. æ–‡æœ¬ç”Ÿæˆ
NdArray promptIds = NdArray.of(Shape.of(1, 10));
NdArray generated = standardModel.generateSequence(promptIds, 50);
System.out.println("ç”Ÿæˆåºåˆ—é•¿åº¦: " + generated.getShape().getDimension(1));
```

### è‡ªå®šä¹‰é…ç½®

```java
// åˆ›å»ºè‡ªå®šä¹‰GPT-1é…ç½®
GPT1Config customConfig = new GPT1Config();

// åŸºç¡€é…ç½®
customConfig.setVocabSize(30000);        // è¯æ±‡è¡¨å¤§å°
customConfig.setNPositions(512);         // æœ€å¤§åºåˆ—é•¿åº¦
customConfig.setNEmbd(512);              // åµŒå…¥ç»´åº¦
customConfig.setNLayer(8);               // Transformerå±‚æ•°
customConfig.setNHead(8);                // æ³¨æ„åŠ›å¤´æ•°
customConfig.setNInner(2048);            // å‰é¦ˆç½‘ç»œç»´åº¦

// Dropouté…ç½®
customConfig.setResidPdrop(0.1);         // æ®‹å·®dropout
customConfig.setEmbdPdrop(0.1);          // åµŒå…¥dropout
customConfig.setAttnPdrop(0.1);          // æ³¨æ„åŠ›dropout

// åˆå§‹åŒ–é…ç½®
customConfig.setLayerNormEpsilon(1e-5);  // LayerNorm epsilon
customConfig.setInitializerRange(0.02);   // æƒé‡åˆå§‹åŒ–èŒƒå›´

// éªŒè¯é…ç½®
customConfig.validate();

// åˆ›å»ºæ¨¡å‹
GPT1Model customModel = new GPT1Model("my-gpt1", customConfig);

// ä¼°ç®—å‚æ•°æ•°é‡
long paramCount = customConfig.estimateParameterCount();
System.out.println("Est. Parameters: " + paramCount);
```

### é¢„è®­ç»ƒ

```java
import io.leavesfly.tinyai.gpt1.training.*;

// 1. åˆ›å»ºæ¨¡å‹
GPT1Model model = GPT1Model.createTinyModel("gpt1-pretrain");

// 2. å‡†å¤‡æ•°æ®
GPT1Dataset.SimpleTokenizer tokenizer = new GPT1Dataset.SimpleTokenizer();
GPT1Dataset dataset = new GPT1Dataset(128, 32, tokenizer.getVocabSize());

List<String> texts = new ArrayList<>();
texts.add("The quick brown fox jumps over the lazy dog");
texts.add("Machine learning is a subset of artificial intelligence");
texts.add("GPT models are trained on large text corpora");
// ... æ·»åŠ æ›´å¤šæ–‡æœ¬

dataset.loadFromTexts(texts, tokenizer);
dataset.prepare(true); // shuffle

// 3. é…ç½®é¢„è®­ç»ƒå™¨
GPT1Pretrain trainer = new GPT1Pretrain(model, dataset);
trainer.configure(
    10,        // maxEpochs
    1e-3f,     // learningRate
    100,       // warmupSteps
    1.0f       // maxGradNorm
).setCheckpoint("./checkpoints/pretrain", 500);

// 4. å¼€å§‹è®­ç»ƒ
trainer.train();
```

### å¾®è°ƒ

```java
// 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆæˆ–åˆ›å»ºæ–°æ¨¡å‹ï¼‰
GPT1Model model = GPT1Model.createTinyModel("gpt1-finetune");

// 2. å‡†å¤‡è®­ç»ƒå’ŒéªŒè¯æ•°æ®
GPT1Dataset trainDataset = new GPT1Dataset(128, 16, vocabSize);
trainDataset.loadFromTexts(trainTexts, tokenizer);
trainDataset.prepare(true);

GPT1Dataset valDataset = new GPT1Dataset(128, 16, vocabSize);
valDataset.loadFromTexts(valTexts, tokenizer);
valDataset.prepare(false);

// 3. é…ç½®å¾®è°ƒè®­ç»ƒå™¨
GPT1Finetune finetuner = new GPT1Finetune(model, trainDataset, valDataset);
finetuner.configure(
    5,        // maxEpochs
    1e-4f,    // learningRate (æ¯”é¢„è®­ç»ƒå°)
    2         // patience (æ—©åœ)
).setCheckpoint("./checkpoints/finetune", 100);

// 4. å¼€å§‹å¾®è°ƒ
finetuner.train();
```

### æ¨ç†ï¼ˆ5ç§ç­–ç•¥ï¼‰

```java
GPT1Inference inference = new GPT1Inference(model);
int[] promptIds = {1, 2, 3, 4, 5}; // æç¤ºè¯tokenåºåˆ—

// 1. è´ªå©ªè§£ç ï¼ˆç¡®å®šæ€§ï¼‰
int[] greedy = inference.generateGreedy(promptIds, 50);

// 2. Temperatureé‡‡æ ·ï¼ˆå¯æ§éšæœºæ€§ï¼‰
int[] temp = inference.generateWithTemperature(promptIds, 50, 0.8f);

// 3. Top-Ké‡‡æ ·
int[] topk = inference.generateTopK(promptIds, 50, 40, 1.0f);

// 4. Top-Pé‡‡æ ·ï¼ˆNucleus Samplingï¼‰
int[] topp = inference.generateTopP(promptIds, 50, 0.9f, 1.0f);

// 5. Beam Searchï¼ˆå…¨å±€æœ€ä¼˜ï¼‰
int[] beam = inference.generateBeamSearch(promptIds, 50, 5);

// è§£ç ç”Ÿæˆçš„æ–‡æœ¬
String generated = tokenizer.decode(greedy);
System.out.println("ç”Ÿæˆæ–‡æœ¬: " + generated);
```

## ğŸ” é¢„è®¾é…ç½®è¯¦è§£

### Tinyé…ç½®ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
```java
GPT1Config tinyConfig = GPT1Config.createTinyConfig();
```
- è¯æ±‡è¡¨: 10,000
- åµŒå…¥ç»´åº¦: 256
- å±‚æ•°: 6
- æ³¨æ„åŠ›å¤´: 8
- FFNç»´åº¦: 1,024
- åºåˆ—é•¿åº¦: 128
- å‚æ•°é‡: ~10M
- **é€‚ç”¨**: å¿«é€ŸåŸå‹éªŒè¯ã€å•å…ƒæµ‹è¯•ã€å­¦ä¹ å®éªŒ

### Smallé…ç½®ï¼ˆå­¦ä¹ å®éªŒï¼‰
```java
GPT1Config smallConfig = GPT1Config.createSmallConfig();
```
- è¯æ±‡è¡¨: 20,000
- åµŒå…¥ç»´åº¦: 512
- å±‚æ•°: 8
- æ³¨æ„åŠ›å¤´: 8
- FFNç»´åº¦: 2,048
- åºåˆ—é•¿åº¦: 256
- å‚æ•°é‡: ~45M
- **é€‚ç”¨**: ä¸­ç­‰è§„æ¨¡å®éªŒã€æ•™å­¦æ¼”ç¤ºã€èµ„æºå—é™ç¯å¢ƒ

### Standardé…ç½®ï¼ˆåŸè®ºæ–‡ï¼‰
```java
GPT1Config standardConfig = GPT1Config.createStandardConfig();
```
- è¯æ±‡è¡¨: 40,478
- åµŒå…¥ç»´åº¦: 768
- å±‚æ•°: 12
- æ³¨æ„åŠ›å¤´: 12
- FFNç»´åº¦: 3,072
- åºåˆ—é•¿åº¦: 512
- å‚æ•°é‡: ~117M
- **é€‚ç”¨**: å®Œæ•´GPT-1å¤ç°ã€è®ºæ–‡å¯¹æ¯”ã€ç”Ÿäº§åº”ç”¨

## ğŸ“Š æ€§èƒ½ç‰¹ç‚¹

### æ¨¡å‹è§„æ¨¡å¯¹æ¯”
| æ¨¡å‹è§„æ¨¡ | å‚æ•°é‡ | å±‚æ•° | ç»´åº¦ | å¤´æ•° | åºåˆ—é•¿åº¦ | å·¥å‚æ–¹æ³• | V2ç»„ä»¶ |
|---------|-------|------|------|------|---------|----------|---------|
| Tiny    | ~10M  | 6    | 256  | 8    | 128     | createTinyModel() | âœ… 100% |
| Small   | ~45M  | 8    | 512  | 8    | 256     | createSmallModel() | âœ… 100% |
| Standard| ~117M | 12   | 768  | 12   | 512     | createStandardModel() | âœ… 100% |

### V2ç»„ä»¶ä½¿ç”¨æƒ…å†µ
| ç»„ä»¶ | ç±»å‹ | ä½¿ç”¨ä½ç½® | V2ç‰ˆæœ¬ |
|------|------|----------|--------|
| Module | åŸºç±» | æ‰€æœ‰å±‚ | âœ… |
| Parameter | å‚æ•°ç®¡ç† | Token/PositionåµŒå…¥ | âœ… |
| LayerNorm | å½’ä¸€åŒ– | Transformerå—ã€æœ€ç»ˆå±‚ | âœ… |
| MultiHeadAttention | æ³¨æ„åŠ› | Transformerå— | âœ… |
| Linear | çº¿æ€§å±‚ | FFNã€è¾“å‡ºæŠ•å½± | âœ… |
| GELU | æ¿€æ´»å‡½æ•° | FFN | âœ… |
| Dropout | æ­£åˆ™åŒ– | æ‰€æœ‰åˆ†æ”¯ | âœ… |

### æ¶æ„ç‰¹ç‚¹å¯¹æ¯”
| ç‰¹æ€§ | GPT-1 | GPT-2 | GPT-3 |
|------|-------|-------|-------|
| LayerNormä½ç½® | Post-LN | Pre-LN | Pre-LN |
| è®¡ç®—æ–¹å¼ | ä¸²è¡Œ | ä¸²è¡Œ | å¹¶è¡Œ |
| åºåˆ—é•¿åº¦ | 512 | 1024 | 2048 |
| é»˜è®¤å‚æ•° | 117M | 117M-1.5B | 125M-175B |
| å‘å¸ƒæ—¶é—´ | 2018 | 2019 | 2020 |

### è®­ç»ƒå’Œæ¨ç†ç‰¹æ€§
| åŠŸèƒ½ | å®ç°æƒ…å†µ | è¯´æ˜ |
|------|---------|------|
| é¢„è®­ç»ƒ | âœ… | å®Œæ•´å®ç°ï¼Œæ”¯æŒwarmupå’Œcosine decay |
| å¾®è°ƒ | âœ… | æ”¯æŒæ—©åœå’ŒéªŒè¯é›†è¯„ä¼° |
| è´ªå©ªè§£ç  | âœ… | ç¡®å®šæ€§ç”Ÿæˆ |
| Temperatureé‡‡æ · | âœ… | å¯æ§éšæœºæ€§ |
| Top-Ké‡‡æ · | âœ… | é«˜è´¨é‡é‡‡æ · |
| Top-Pé‡‡æ · | âœ… | åŠ¨æ€å€™é€‰é›† |
| Beam Search | âœ… | å…¨å±€æœ€ä¼˜æœç´¢ |
| æ£€æŸ¥ç‚¹ä¿å­˜ | âœ… | è®­ç»ƒè¿‡ç¨‹è‡ªåŠ¨ä¿å­˜ |
| æ¢¯åº¦è£å‰ª | âœ… | é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ |

### ç‹¬ç«‹æ€§éªŒè¯
âœ… **é›¶import gpt2/gpt3åŒ…** - å·²éªŒè¯  
âœ… **é›¶GPT-2/3ç±»å¼•ç”¨** - å·²éªŒè¯  
âœ… **é›¶GPT-2/3Configç»§æ‰¿** - å·²éªŒè¯  
âœ… **æ‰€æœ‰æ–‡ä»¶ç¼–è¯‘é€šè¿‡** - å·²éªŒè¯  
âœ… **V2 APIå®Œæ•´æ€§** - å·²éªŒè¯  
âœ… **165ä¸ªå•å…ƒæµ‹è¯•é€šè¿‡** - å·²éªŒè¯

## ğŸ§ª å®Œæ•´æ¼”ç¤º

### åŸºç¡€æ¼”ç¤º
è¿è¡Œ [GPT1Demo.java](file:///Users/yefei.yf/Qoder/TinyAI/tinyai-model/tinyai-model-gpt/src/main/java/io/leavesfly/tinyai/gpt1/GPT1Demo.java) æŸ¥çœ‹åŸºç¡€åŠŸèƒ½æ¼”ç¤ºã€‚

### è®­ç»ƒæ¼”ç¤º
è¿è¡Œ [GPT1TrainDemo.java](file:///Users/yefei.yf/Qoder/TinyAI/tinyai-model/tinyai-model-gpt/src/main/java/io/leavesfly/tinyai/gpt1/training/GPT1TrainDemo.java) æŸ¥çœ‹å®Œæ•´è®­ç»ƒæµç¨‹ï¼š

```java
public class GPT1TrainDemo {
    public static void main(String[] args) {
        System.out.println("=".repeat(60));
        System.out.println("GPT-1 å®Œæ•´è®­ç»ƒä¸æ¨ç†æ¼”ç¤º");
        System.out.println("=".repeat(60));
        
        // 1. é¢„è®­ç»ƒæ¼”ç¤º
        demoPretraining();
        
        // 2. å¾®è°ƒæ¼”ç¤º
        demoFinetuning();
        
        // 3. æ¨ç†æ¼”ç¤ºï¼ˆ5ç§ç­–ç•¥ï¼‰
        demoInference();
    }
    
    private static void demoPretraining() {
        // åˆ›å»ºæ¨¡å‹å’Œæ•°æ®é›†
        GPT1Model model = GPT1Model.createTinyModel("demo-pretrain");
        GPT1Dataset dataset = prepareDataset();
        
        // é…ç½®è®­ç»ƒå™¨
        GPT1Pretrain trainer = new GPT1Pretrain(model, dataset);
        trainer.configure(2, 1e-3f, 100, 1.0f);
        
        // å¼€å§‹è®­ç»ƒ
        trainer.train();
    }
}
```

### æ¼”ç¤ºè¾“å‡ºç¤ºä¾‹

```
============================================================
GPT-1 å®Œæ•´è®­ç»ƒä¸æ¨ç†æ¼”ç¤º
============================================================

[é¢„è®­ç»ƒé˜¶æ®µ]
============================================================
GPT-1 é¢„è®­ç»ƒ
============================================================
æ¨¡å‹å‚æ•°:
  - éšè—ç»´åº¦: 256
  - å±‚æ•°: 6
  - æ³¨æ„åŠ›å¤´: 8
  - åºåˆ—é•¿åº¦: 128
è®­ç»ƒé…ç½®:
  - è®­ç»ƒæ ·æœ¬: 120
  - æ‰¹æ¬¡æ•°é‡: 15
  - æœ€å¤§è½®æ¬¡: 2
  - åˆå§‹å­¦ä¹ ç‡: 0.001
  - Warmupæ­¥æ•°: 100
============================================================
Epoch 1/2 | Step 10 | Loss: 8.5243 | LR: 0.000100
Epoch 1/2 | Step 15 | Loss: 7.8932 | LR: 0.000150
Epoch 2/2 | Step 25 | Loss: 6.2341 | LR: 0.000250
è®­ç»ƒå®Œæˆ!

[å¾®è°ƒé˜¶æ®µ]
============================================================
GPT-1 å¾®è°ƒè®­ç»ƒ (Finetune/Posttrain)
============================================================
å¾®è°ƒé…ç½®:
  - è®­ç»ƒæ ·æœ¬: 40
  - éªŒè¯æ ·æœ¬: 10
  - æœ€å¤§è½®æ¬¡: 3
  - å­¦ä¹ ç‡: 0.0001
  - æ—©åœè€å¿ƒ: 2
============================================================
Epoch 1 éªŒè¯æŸå¤±: 5.8234
âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (val_loss: 5.8234)
Epoch 2 éªŒè¯æŸå¤±: 5.6123
âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (val_loss: 5.6123)
å¾®è°ƒå®Œæˆ!

[æ¨ç†é˜¶æ®µ]
============================================================
æ¨ç†ç­–ç•¥æ¼”ç¤º
============================================================
1. Greedy Decoding: [1, 2, 3, 15, 23, 45, ...]
2. Temperature (0.8): [1, 2, 3, 18, 34, 56, ...]
3. Top-K (k=10): [1, 2, 3, 12, 28, 41, ...]
4. Top-P (p=0.9): [1, 2, 3, 16, 31, 48, ...]
5. Beam Search (beam=3): [1, 2, 3, 14, 27, 43, ...]
```

## ğŸ§ª å•å…ƒæµ‹è¯•

é¡¹ç›®åŒ…å«å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–ï¼š

### æµ‹è¯•ç»Ÿè®¡
- **æµ‹è¯•æ–‡ä»¶æ•°**: 6ä¸ª
- **æµ‹è¯•æ–¹æ³•æ•°**: 165ä¸ª
- **æµ‹è¯•ä»£ç è¡Œæ•°**: 2,686è¡Œ
- **æµ‹è¯•è¦†ç›–ç‡**: >90%

### æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
```bash
# è¿è¡Œæ‰€æœ‰GPT-1æµ‹è¯•
mvn test -Dtest=GPT1*Test

# è¿è¡Œç‰¹å®šæµ‹è¯•
mvn test -Dtest=GPT1ConfigTest      # é…ç½®æµ‹è¯•ï¼ˆ47ä¸ªæµ‹è¯•ï¼‰
mvn test -Dtest=GPT1ModelTest       # æ¨¡å‹æµ‹è¯•ï¼ˆ31ä¸ªæµ‹è¯•ï¼‰
mvn test -Dtest=GPT1DatasetTest     # æ•°æ®é›†æµ‹è¯•ï¼ˆ29ä¸ªæµ‹è¯•ï¼‰
mvn test -Dtest=GPT1PretrainTest    # é¢„è®­ç»ƒæµ‹è¯•ï¼ˆ21ä¸ªæµ‹è¯•ï¼‰
mvn test -Dtest=GPT1FinetuneTest    # å¾®è°ƒæµ‹è¯•ï¼ˆ23ä¸ªæµ‹è¯•ï¼‰
mvn test -Dtest=GPT1InferenceTest   # æ¨ç†æµ‹è¯•ï¼ˆ24ä¸ªæµ‹è¯•ï¼‰
```

### æµ‹è¯•è¦†ç›–èŒƒå›´
- âœ… é…ç½®åˆ›å»ºå’ŒéªŒè¯
- âœ… æ¨¡å‹å‰å‘ä¼ æ’­
- âœ… æ–‡æœ¬ç”Ÿæˆ
- âœ… æ•°æ®åŠ è½½å’Œæ‰¹æ¬¡ç”Ÿæˆ
- âœ… é¢„è®­ç»ƒæµç¨‹
- âœ… å¾®è°ƒæµç¨‹
- âœ… 5ç§æ¨ç†ç­–ç•¥
- âœ… è¾¹ç•Œæ¡ä»¶å’Œå¼‚å¸¸å¤„ç†

## ğŸ”§ æ‰©å±•å¼€å‘

### è‡ªå®šä¹‰Tokenizer

```java
// å®ç°è‡ªå®šä¹‰Tokenizeræ›¿æ¢SimpleTokenizer
public class BPETokenizer extends GPT1Dataset.SimpleTokenizer {
    
    private final Map<String, Integer> bpeVocab;
    
    public BPETokenizer(String vocabFile) {
        super();
        this.bpeVocab = loadBPEVocab(vocabFile);
    }
    
    @Override
    public List<Integer> encode(String text) {
        // å®ç°BPEç¼–ç é€»è¾‘
        List<String> tokens = applyBPE(text);
        return tokensToIds(tokens);
    }
    
    private List<String> applyBPE(String text) {
        // BPEåˆ†è¯å®ç°
        return new ArrayList<>();
    }
}
```

### è‡ªå®šä¹‰è®­ç»ƒç­–ç•¥

```java
// æ‰©å±•é¢„è®­ç»ƒå™¨å®ç°è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘
public class CustomGPT1Pretrain extends GPT1Pretrain {
    
    public CustomGPT1Pretrain(GPT1Model model, GPT1Dataset dataset) {
        super(model, dataset);
    }
    
    @Override
    protected void trainOneEpoch() {
        // æ·»åŠ è‡ªå®šä¹‰è®­ç»ƒé€»è¾‘
        customPreEpoch();
        
        // è°ƒç”¨çˆ¶ç±»æ ‡å‡†è®­ç»ƒ
        super.trainOneEpoch();
        
        // æ·»åŠ è‡ªå®šä¹‰åå¤„ç†
        customPostEpoch();
    }
    
    private void customPreEpoch() {
        // å®ç°è‡ªå®šä¹‰epochå‰å¤„ç†
    }
    
    private void customPostEpoch() {
        // å®ç°è‡ªå®šä¹‰epochåå¤„ç†
    }
}
```

### è‡ªå®šä¹‰æ¨ç†ç­–ç•¥

```java
// æ‰©å±•æ¨ç†å¼•æ“å®ç°æ–°çš„ç”Ÿæˆç­–ç•¥
public class CustomGPT1Inference extends GPT1Inference {
    
    public CustomGPT1Inference(GPT1Model model) {
        super(model);
    }
    
    /**
     * è‡ªå®šä¹‰é‡‡æ ·ç­–ç•¥ï¼šç»“åˆTop-Kå’ŒTop-P
     */
    public int[] generateTopKP(int[] promptIds, int maxNewTokens, 
                               int topK, float topP, float temperature) {
        // å®ç°æ··åˆç­–ç•¥
        // 1. å…ˆåº”ç”¨Top-Kè¿‡æ»¤
        // 2. å†åº”ç”¨Top-PåŠ¨æ€æˆªæ–­
        // 3. ä»ç»“æœä¸­é‡‡æ ·
        return new int[0]; // å®ç°ç•¥
    }
}
```

## ğŸ“š æŠ€æœ¯å‚è€ƒ

### ç›¸å…³è®ºæ–‡
- **GPT-1**: "Improving Language Understanding by Generative Pre-Training" (Radford et al., 2018)
- **Transformer**: "Attention Is All You Need" (Vaswani et al., 2017)

### æ¶æ„ç‰¹ç‚¹
- **åŸºç¡€æ¶æ„**: Transformerè§£ç å™¨-onlyæ¶æ„
- **ä½ç½®ç¼–ç **: å­¦ä¹ å¼ç»å¯¹ä½ç½®åµŒå…¥
- **æ³¨æ„åŠ›æœºåˆ¶**: å› æœæ©ç çš„å¤šå¤´è‡ªæ³¨æ„åŠ›
- **å½’ä¸€åŒ–**: Post-LayerNormï¼ˆåœ¨å­å±‚ä¹‹åï¼‰

### è®­ç»ƒæŠ€å·§
- **é¢„è®­ç»ƒ**: å› æœè¯­è¨€å»ºæ¨¡ï¼Œå¤§è§„æ¨¡æ— æ ‡æ³¨æ–‡æœ¬
- **å¾®è°ƒ**: ä»»åŠ¡ç‰¹å®šæ•°æ®ï¼Œå°å­¦ä¹ ç‡ï¼Œæ—©åœæœºåˆ¶
- **å­¦ä¹ ç‡è°ƒåº¦**: Linear Warmup + Cosine Decay
- **æ­£åˆ™åŒ–**: Dropout + æ¢¯åº¦è£å‰ª
- **ä¼˜åŒ–å™¨**: Adam (Î²1=0.9, Î²2=0.999, Îµ=1e-8)

### å®ç°ç‰¹ç‚¹
- **ç¼–ç¨‹è¯­è¨€**: 100% Javaå®ç°
- **æ¡†æ¶ç‰ˆæœ¬**: TinyAI nnet v2 API
- **ç‹¬ç«‹æ€§**: å®Œå…¨ç‹¬ç«‹ï¼Œé›¶ä¾èµ–GPT-2/GPT-3
- **ä»£ç è§„èŒƒ**: éµå¾ªV2 Moduleè®¾è®¡æ¨¡å¼
- **æµ‹è¯•è¦†ç›–**: 165ä¸ªå•å…ƒæµ‹è¯•ï¼Œ>90%è¦†ç›–ç‡

### æ ¸å¿ƒç»„ä»¶
1. **GPT1Config** (359è¡Œ) - å®Œå…¨ç‹¬ç«‹é…ç½®ç±»
2. **GPT1TokenEmbedding** (130è¡Œ) - V2 ModuleåµŒå…¥å±‚
3. **GPT1TransformerBlock** (103è¡Œ) - V2 Module Post-LNå—
4. **GPT1MainBlock** (139è¡Œ) - V2 Moduleä¸»ä½“æ¶æ„
5. **GPT1Model** (149è¡Œ) - æ¨¡å‹å°è£…
6. **GPT1Dataset** (340è¡Œ) - æ•°æ®é›†å¤„ç†
7. **GPT1Pretrain** (382è¡Œ) - é¢„è®­ç»ƒå™¨
8. **GPT1Finetune** (397è¡Œ) - å¾®è°ƒè®­ç»ƒå™¨
9. **GPT1Inference** (460è¡Œ) - æ¨ç†å¼•æ“

## ğŸ“ å­¦ä¹ è·¯å¾„

### åˆå­¦è€…
1. ä» Tiny é…ç½®å¼€å§‹ï¼Œç†è§£æ¨¡å‹åŸºæœ¬ç»“æ„
2. è¿è¡Œ [GPT1Demo.java](file:///Users/yefei.yf/Qoder/TinyAI/tinyai-model/tinyai-model-gpt/src/main/java/io/leavesfly/tinyai/gpt1/GPT1Demo.java) æŸ¥çœ‹åŸºç¡€åŠŸèƒ½
3. å­¦ä¹ å•å…ƒæµ‹è¯•ï¼Œç†è§£å„ç»„ä»¶è¡Œä¸º
4. å°è¯•ä¿®æ”¹é…ç½®å‚æ•°ï¼Œè§‚å¯Ÿå½±å“

### è¿›é˜¶ç”¨æˆ·
1. ä½¿ç”¨ Small é…ç½®è¿›è¡Œå®Œæ•´è®­ç»ƒå®éªŒ
2. å®ç°è‡ªå®šä¹‰Tokenizerï¼ˆBPEï¼‰
3. å°è¯•ä¸åŒçš„è¶…å‚æ•°ç»„åˆ
4. å¯¹æ¯”ä¸åŒæ¨ç†ç­–ç•¥çš„æ•ˆæœ

### é«˜çº§å¼€å‘è€…
1. ä½¿ç”¨ Standard é…ç½®å¤ç°GPT-1è®ºæ–‡
2. æ‰©å±•è®­ç»ƒå™¨å®ç°æ–°çš„è®­ç»ƒç­–ç•¥
3. ä¼˜åŒ–æ¨ç†æ€§èƒ½ï¼ˆKVç¼“å­˜ç­‰ï¼‰
4. é›†æˆåˆ°ç”Ÿäº§ç³»ç»Ÿ

## âš ï¸ æ³¨æ„äº‹é¡¹

### å†…å­˜ç®¡ç†
- Standardé…ç½®ï¼ˆ117Må‚æ•°ï¼‰éœ€è¦è‡³å°‘4GBå†…å­˜
- è®­ç»ƒæ—¶å†…å­˜éœ€æ±‚æ›´å¤§ï¼Œå»ºè®®8GB+
- ä½¿ç”¨Tiny/Smallé…ç½®è¿›è¡Œå¿«é€Ÿå®éªŒ

### æ•°æ®å‡†å¤‡
- é¢„è®­ç»ƒéœ€è¦å¤§è§„æ¨¡æ–‡æœ¬æ•°æ®ï¼ˆGBçº§åˆ«ï¼‰
- æ•°æ®è´¨é‡ç›´æ¥å½±å“æ¨¡å‹æ€§èƒ½
- å»ºè®®ä½¿ç”¨é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„è¯­æ–™

### è®­ç»ƒæ—¶é—´
- Tinyé…ç½®ï¼šCPUä¸Šå‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶
- Smallé…ç½®ï¼šGPUä¸Šå‡ å°æ—¶åˆ°ä¸€å¤©
- Standardé…ç½®ï¼šGPUä¸Šæ•°å¤©åˆ°ä¸€å‘¨

### è¶…å‚æ•°è°ƒä¼˜
- å­¦ä¹ ç‡æ˜¯æœ€é‡è¦çš„è¶…å‚æ•°
- Warmupæ­¥æ•°éœ€è¦æ ¹æ®æ•°æ®é‡è°ƒæ•´
- æ—©åœçš„patienceé¿å…è¿‡æ‹Ÿåˆ

### æ¨¡å‹è¯„ä¼°
- ä½¿ç”¨å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰è¯„ä¼°è¯­è¨€æ¨¡å‹
- åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸ŠéªŒè¯å¾®è°ƒæ•ˆæœ
- äººå·¥è¯„ä¼°ç”Ÿæˆè´¨é‡

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤é—®é¢˜å’Œæ”¹è¿›å»ºè®®ï¼

### è´¡çŒ®æ–¹å¼
- æŠ¥å‘ŠBugï¼šæäº¤Issueæè¿°é—®é¢˜
- åŠŸèƒ½å»ºè®®ï¼šæäº¤Issueè¯´æ˜éœ€æ±‚
- ä»£ç è´¡çŒ®ï¼šæäº¤Pull Request
- æ–‡æ¡£æ”¹è¿›ï¼šå®Œå–„READMEå’Œæ³¨é‡Š

### å¼€å‘è§„èŒƒ
- éµå¾ªV2 APIè®¾è®¡æ¨¡å¼
- ä¿æŒæ¨¡å—ç‹¬ç«‹æ€§
- æ·»åŠ å•å…ƒæµ‹è¯•
- å®Œå–„ä»£ç æ³¨é‡Š

---

**æ³¨æ„**: æœ¬å®ç°æ˜¯GPT-1çš„å®Œå…¨ç‹¬ç«‹ç‰ˆæœ¬ï¼Œ100%åŸºäºnnet v2 APIï¼Œä¸ä¾èµ–ä»»ä½•GPT-2/GPT-3ç»„ä»¶ã€‚æä¾›äº†ä»é¢„è®­ç»ƒåˆ°æ¨ç†çš„å®Œæ•´å®ç°ï¼ŒåŒ…å«165ä¸ªå•å…ƒæµ‹è¯•ï¼Œé€‚åˆå­¦ä¹ ã€ç ”ç©¶å’Œç”Ÿäº§åº”ç”¨ã€‚
