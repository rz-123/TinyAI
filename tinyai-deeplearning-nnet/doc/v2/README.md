# TinyAI Neural Network V2 æ¨¡å—

## æ¦‚è¿°

V2 ç‰ˆæœ¬æ˜¯ TinyAI ç¥ç»ç½‘ç»œæ¨¡å—çš„å…¨æ–°å®ç°ï¼Œé‡‡ç”¨ç±»ä¼¼ PyTorch çš„è®¾è®¡ç†å¿µï¼Œæä¾›æ›´å¼ºå¤§çš„å‚æ•°ç®¡ç†ã€å»¶è¿Ÿåˆå§‹åŒ–ã€æ¨¡å¼åˆ‡æ¢ç­‰é«˜çº§ç‰¹æ€§ã€‚

## ä¸»è¦ç‰¹æ€§

### 1. ç»Ÿä¸€çš„å‚æ•°æ³¨å†Œæœºåˆ¶
- `registerParameter()` ç»Ÿä¸€æ³¨å†Œå¯è®­ç»ƒå‚æ•°
- `registerBuffer()` æ³¨å†Œéå¯è®­ç»ƒå¼ é‡ï¼ˆå¦‚ BatchNorm çš„ç»Ÿè®¡é‡ï¼‰
- `namedParameters()` è‡ªåŠ¨ç”Ÿæˆåˆ†å±‚å‘½åè·¯å¾„

### 2. å»¶è¿Ÿåˆå§‹åŒ–æ”¯æŒ
- `LazyModule` åŸºç±»æ”¯æŒæ ¹æ®è¾“å…¥åŠ¨æ€æ¨æ–­å‚æ•°å½¢çŠ¶
- `LazyLinear`ã€`LazyConv2d` ç­‰å±‚æ— éœ€é¢„å…ˆæŒ‡å®šè¾“å…¥ç»´åº¦

### 3. è®­ç»ƒ/æ¨ç†æ¨¡å¼åˆ‡æ¢
- `train()` å’Œ `eval()` æ–¹æ³•æ§åˆ¶å…¨å±€æ¨¡å¼
- Dropoutã€BatchNorm ç­‰å±‚è‡ªåŠ¨é€‚é…ä¸åŒæ¨¡å¼

### 4. çµæ´»çš„åˆå§‹åŒ–ç­–ç•¥
- `Initializer` æ¥å£å’Œä¸°å¯Œçš„å†…ç½®åˆå§‹åŒ–å™¨
- `resetParameters()` ç»Ÿä¸€çš„å‚æ•°åˆå§‹åŒ–æ¥å£
- æ”¯æŒå¤–éƒ¨è‡ªå®šä¹‰åˆå§‹åŒ–ç­–ç•¥

### 5. å®Œæ•´çš„çŠ¶æ€ç®¡ç†
- `stateDict()` å¯¼å‡ºå®Œæ•´æ¨¡å‹çŠ¶æ€
- `loadStateDict()` åŠ è½½é¢„è®­ç»ƒæƒé‡
- æ”¯æŒéƒ¨åˆ†çŠ¶æ€åŠ è½½å’Œæ¨¡å‹è¿ç§»

## ç›®å½•ç»“æ„

```
v2/
â”œâ”€â”€ core/              # æ ¸å¿ƒæŠ½è±¡
â”‚   â”œâ”€â”€ Module.java    # æ¨¡å—åŸºç±»ï¼ˆç»§æ‰¿Functionï¼‰
â”‚   â”œâ”€â”€ Parameter.java # å¢å¼ºçš„å‚æ•°ç±»
â”‚   â””â”€â”€ LazyModule.java# å»¶è¿Ÿåˆå§‹åŒ–åŸºç±»
â”‚
â”œâ”€â”€ init/              # åˆå§‹åŒ–å™¨
â”‚   â”œâ”€â”€ Initializer.java
â”‚   â”œâ”€â”€ Initializers.java
â”‚   â”œâ”€â”€ ZerosInitializer.java
â”‚   â”œâ”€â”€ KaimingInitializer.java
â”‚   â””â”€â”€ XavierInitializer.java
â”‚
â”œâ”€â”€ layer/             # å±‚å®ç°
â”‚   â”œâ”€â”€ dnn/          # å…¨è¿æ¥å±‚
â”‚   â”‚   â”œâ”€â”€ Linear.java
â”‚   â”‚   â”œâ”€â”€ LazyLinear.java
â”‚   â”‚   â””â”€â”€ Dropout.java
â”‚   â”œâ”€â”€ activation/   # æ¿€æ´»å‡½æ•°
â”‚   â”‚   â”œâ”€â”€ ReLU.java
â”‚   â”‚   â”œâ”€â”€ Sigmoid.java
â”‚   â”‚   â”œâ”€â”€ Tanh.java
â”‚   â”‚   â””â”€â”€ SoftMax.java
â”‚   â”œâ”€â”€ norm/         # å½’ä¸€åŒ–å±‚
â”‚   â”‚   â”œâ”€â”€ LayerNorm.java
â”‚   â”‚   â””â”€â”€ BatchNorm1d.java  # âœ¨ æ–°å¢
â”‚   â”œâ”€â”€ conv/         # å·ç§¯å±‚ï¼ˆå¾…å®ç°ï¼‰
â”‚   â”œâ”€â”€ rnn/          # å¾ªç¯å±‚ï¼ˆå¾…å®ç°ï¼‰
â”‚   â””â”€â”€ transformer/  # Transformerç»„ä»¶ï¼ˆå¾…å®ç°ï¼‰
â”‚
â”œâ”€â”€ container/         # å®¹å™¨æ¨¡å—
â”‚   â”œâ”€â”€ Sequential.java
â”‚   â”œâ”€â”€ ModuleList.java
â”‚   â””â”€â”€ ModuleDict.java
â”‚
â””â”€â”€ utils/             # å·¥å…·ç±»
    â””â”€â”€ StateDict.java
```

## å¿«é€Ÿå¼€å§‹

### æ ‡å‡†çº¿æ€§å±‚

```java
import io.leavesfly.tinyai.nnet.v2.core.Module;
import io.leavesfly.tinyai.nnet.v2.layer.dnn.Linear;

// åˆ›å»ºçº¿æ€§å±‚
Module linear = new Linear("fc", 128, 64, true);

// å‰å‘ä¼ æ’­
Variable output = linear.forward(input);

// è®¿é—®å‚æ•°
Parameter weight = linear.getParameter("weight");
Parameter bias = linear.getParameter("bias");
```

### å»¶è¿Ÿåˆå§‹åŒ–

```java
import io.leavesfly.tinyai.nnet.v2.layer.dnn.LazyLinear;

// æ— éœ€æŒ‡å®šè¾“å…¥ç»´åº¦
Module lazy = new LazyLinear("fc", 64, true);

// é¦–æ¬¡å‰å‘ä¼ æ’­æ—¶è‡ªåŠ¨æ¨æ–­å¹¶åˆå§‹åŒ–
Variable output = lazy.forward(input);  // æ ¹æ®input.shapeæ¨æ–­
```

### æ¨¡å¼åˆ‡æ¢

```java
// è®­ç»ƒæ¨¡å¼
model.train();
output = model.forward(input);  // Dropoutå¯ç”¨

// æ¨ç†æ¨¡å¼
model.eval();
output = model.forward(input);  // Dropoutç¦ç”¨
```

### è‡ªå®šä¹‰åˆå§‹åŒ–

```java
import io.leavesfly.tinyai.nnet.v2.init.Initializers;

// æ–¹å¼ä¸€ï¼šåœ¨resetParametersä¸­ä½¿ç”¨
@Override
public void resetParameters() {
    Initializers.kaimingUniform(weight.data(), 0, "fan_in", "relu");
    Initializers.zeros(bias.data());
}

// æ–¹å¼äºŒï¼šå¤–éƒ¨ç»Ÿä¸€åˆå§‹åŒ–
model.apply(module -> {
    if (module instanceof Linear) {
        Initializers.xavierNormal(module.getParameter("weight").data());
    }
});
```

### BatchNorm1d ä½¿ç”¨

```java
import io.leavesfly.tinyai.nnet.v2.layer.norm.BatchNorm1d;

// åˆ›å»ºBatchNormå±‚
BatchNorm1d bn = new BatchNorm1d("bn1", 64);

// è®­ç»ƒæ¨¡å¼ï¼šä½¿ç”¨æ‰¹æ¬¡ç»Ÿè®¡é‡
bn.train();
Variable output = bn.forward(input);  // è‡ªåŠ¨æ›´æ–°running stats

// æ¨ç†æ¨¡å¼ï¼šä½¿ç”¨å›ºå®šç»Ÿè®¡é‡
bn.eval();
Variable output = bn.forward(input);  // ä½¿ç”¨running stats

// è®¿é—®ç»Ÿè®¡é‡
NdArray runningMean = bn.getRunningMean();
NdArray runningVar = bn.getRunningVar();
```

## V1 vs V2 å¯¹æ¯”

| ç‰¹æ€§ | V1 (LayerAble) | V2 (Module) |
|------|---------------|-------------|
| ç»§æ‰¿å…³ç³» | LayerAble â†’ Function | Module â†’ Function |
| å‚æ•°ç®¡ç† | æ‰‹åŠ¨Mapç®¡ç† | registerParameter/Buffer |
| å‘½åè·¯å¾„ | æ‰‹åŠ¨æ‹¼æ¥ | è‡ªåŠ¨åˆ†å±‚è·¯å¾„ |
| æ¨¡å¼åˆ‡æ¢ | âŒ ä¸æ”¯æŒ | âœ… train()/eval() |
| å»¶è¿Ÿåˆå§‹åŒ– | âŒ ä¸æ”¯æŒ | âœ… LazyModule |
| çŠ¶æ€åºåˆ—åŒ– | éƒ¨åˆ†æ”¯æŒ | âœ… stateDict/loadStateDict |
| è‡ªåŠ¨å¾®åˆ† | âœ… æ”¯æŒ | âœ… æ”¯æŒï¼ˆç»§æ‰¿Functionï¼‰|

## å…¼å®¹æ€§

V2 ä¸ V1 å®Œå…¨éš”ç¦»ï¼Œäº’ä¸å½±å“ï¼š
- V1 ä»£ç ä¿æŒç¨³å®šï¼Œä¸åšä»»ä½•ä¿®æ”¹
- V2 ä½¿ç”¨ç‹¬ç«‹çš„åŒ…å‘½åç©ºé—´ `io.leavesfly.tinyai.nnet.v2`
- ä¸¤è€…å¯åœ¨åŒä¸€é¡¹ç›®ä¸­å…±å­˜

## æ–‡æ¡£ç›®å½•

- [APIå‚è€ƒ](api-reference.md) - è¯¦ç»†çš„APIæ–‡æ¡£
- [è¿ç§»æŒ‡å—](migration-guide.md) - V1åˆ°V2è¿ç§»æ­¥éª¤
- [è®¾è®¡åŸåˆ™](design-principles.md) - V2è®¾è®¡ç†å¿µè¯´æ˜

## å¼€å‘çŠ¶æ€

### æ ¸å¿ƒåŠŸèƒ½ï¼ˆâœ… å·²å®Œæˆï¼‰
- [x] é˜¶æ®µä¸€ï¼šV2åŸºç¡€æ¶æ„æ­å»º
- [x] é˜¶æ®µäºŒï¼šV2é«˜çº§ç‰¹æ€§å®ç°ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ã€å®¹å™¨æ¨¡å—ï¼‰
- [x] BatchNorm1d å½’ä¸€åŒ–å±‚å®ç°
- [x] æµ‹è¯•å·¥å…·ç±»ï¼ˆAssertHelperã€GradientCheckerã€TestDataGeneratorï¼‰

### æµ‹è¯•è¦†ç›–ï¼ˆğŸš§ è¿›è¡Œä¸­ï¼‰
- [x] BatchNorm1d å®Œæ•´å•å…ƒæµ‹è¯•ï¼ˆ11ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰
- [ ] Moduleæ ¸å¿ƒç»„ä»¶æµ‹è¯•
- [ ] Linearå±‚åŠŸèƒ½æµ‹è¯•
- [ ] æ¿€æ´»å‡½æ•°æµ‹è¯•
- [ ] åˆå§‹åŒ–å™¨æµ‹è¯•
- [ ] é›†æˆæµ‹è¯•

### é«˜çº§å±‚ï¼ˆğŸ“… è®¡åˆ’ä¸­ï¼‰
- [ ] é˜¶æ®µä¸‰ï¼šRNNå±‚ï¼ˆLSTMã€GRUã€SimpleRNNï¼‰
- [ ] Transformerç»„ä»¶ï¼ˆMultiHeadAttentionã€EncoderLayerï¼‰
- [ ] å·ç§¯å±‚ï¼ˆConv2dã€LazyConv2dã€Poolingï¼‰

## è®¸å¯è¯

ä¸ TinyAI ä¸»é¡¹ç›®ä¿æŒä¸€è‡´
